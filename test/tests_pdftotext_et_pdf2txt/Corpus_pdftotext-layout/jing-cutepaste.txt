                    C u t and P a s t e B a s e d Text S u m m a r i z a t i o n
                          Hongyan   Jing and Kathleen         R. McKeown
                                Department of Computer Science
                                        Columbia University
                                   N e w Y o r k , N Y 10027, U S A
                                  hjing, kathyQcs.columbia.edu




                    Abstract                              ing operations. We identified six operations that
We present a cut and paste based text summa-              can be used alone or together to transform extracted
rizer, which uses operations derived from an anal-        sentences into sentences in human-written abstracts.
ysis of human written abstracts. The summarizer           The operations were identified based on manual and
edits extracted sentences, using reduction to remove      automatic comparison of human-written abstracts
inessential phrases and combination to merge re-          and the original articles. Examples include sentence
suiting phrases together as coherent sentences. Our       reduction, sentence combination, syntactic transfor-
work includes a statistically based sentence decom-       mation, and lexical paraphrasing.
position program that identifies where the phrases of         (2) D e v e l o p m e n t o f an automatic system to
a summary originate in the original document, pro-        p e r f o r m cut and paste operations. Two opera-
ducing an aligned corpus of summaries and articles        tions - sentence reduction and sentence combination
which we used to develop the summarizer.                  - are most effective in transforming extracted sen-
                                                          tences into summary sentences that are as concise
1   Introduction                                          and coherent as in human-written abstracts. We
                                                          implemented a sentence reduction module that re-
There is a big gap between the summaries produced
                                                          moves extraneous phrases from extracted sentences,
by current automatic summarizers and the abstracts
                                                          and a sentence combination module that merges the
written by human professionals. Certainly one fac-
                                                          extracted sentences or the reduced forms resulting
tor contributing to this gap is that automatic sys-
                                                          from sentence reduction. Our sentence reduction
tems can not always correctly identify the important
                                                          model determines what to cut based on multiple
topics of an article. Another factor, however, which
                                                          sources of information, including syntactic knowl-
has received little attention, is that automatic sum-
                                                          edge, context, and statistics learned from corpus
marizers have poor text generation techniques. Most
                                                          analysis. It improves the conciseness of extracted
automatic summarizers rely on extracting key sen-
                                                          sentences, making them concise and on target. Our
tences or paragraphs from an article to produce a
                                                          sentence combination module implements combina-
summary. Since the extracted sentences are discon-
                                                          tion rules that were identified by observing examples
nected in the original article, when they are strung
                                                          written by human professionals. It improves the co-
together, the resulting summary can be inconcise,
                                                          herence of extracted sentences.
incoherent, and sometimes even misleading.
   We present a cut and paste based text sum-               (3) Decomposing human-wrltten s u m m a r y
marization technique, aimed at reducing the gap           sentences. The cut and paste technique we propose
between automatically generated summaries and             here is a new computational model which we based
human-written abstracts.        Rather than focusing      on analysis of human-written abstracts. To do this
on how to identify key sentences, as do other re-         analysis, we developed an automatic system that can
searchers, we study how to generate the text of a         match a phrase in a human-written abstract to the
summary once key sentences have been extracted.           corresponding phrase in the article, identifying its
   The main idea of cut and paste summarization           most likely location. This decomposition program
is to reuse the text in an article to generate the        allows us to analyze the construction of sentences
summary. However, instead of simply extracting            in a human-written abstract. Its results have been
sentences as current summarizers do, the cut and          used to train and test the sentence reduction and
paste system will "smooth" the extracted sentences        sentence combination module.
by editing them. Such edits mainly involve cutting           In Section 2, we discuss the cut and paste tech-
phrases and pasting them together in novel ways.          nique in general, from both a professional and com-
   The key features of this work are:                     putational perspective. We also describe the six cut
   (1) The identification of cutting and past-            and paste operations. In Section 3, we describe the

                                                    178
system architecture. The major components of the                   Document sentence: When it arrives some-
system, including sentence reduction, sentence com-                time next year in new T V sets, the V-chip will
bination, decomposition, and sentence selection, are               give parents a new and potentially revolution-
described in Section 4. The evaluation results are                 ary device to block out programs they don't
shown in Section 5. Related work is discussed in                   want their children to see.
Section 6. Finally, we conclude and discuss future                 Summary sentence: The V-chip will give par-
work.                                                              ents a device to block out programs they don't
                                                                   want their children to see.

2     Cut   and paste in summarization                            The deleted material can be at any granularity: a
                                                                word, a phrase, or a clause. Multiple components
2.1    R e l a t e d w o r k in professional                    can be removed.
       summarizing                                                (2) sentence combination
                                                                   Merge material from several sentences. It can be
Professionals take two opposite positions on whether
                                                                used together with sentence reduction, as illustrated
a summary should be produced by cutting and past-
                                                                in the following example, which also uses paraphras-
ing the original text. One school of scholars is
                                                                ing:
opposed; "(use) your own words... Do not keep
too close to the words before you", states an early                Text Sentence 1: But it also raises serious
book on abstracting for American high school stu-                  questions about the privacy of such highly
dents (Thurber, 1924). Another study, however,                     personal information wafting about the digital
shows that professional abstractors actually rely on               world.
cutting and pasting to produce summaries: "Their                   Text Sentence 2: The issue thus fits squarely
professional role tells abstractors to avoid inventing             into the broader debate about privacy and se-
anything. They follow the author as closely as pos-                curity on the internet, whether it involves pro-
sible and reintegrate the most important points of                 tecting credit card number or keeping children
a document in a shorter text" (Endres-Niggemeyer                   from offensive information.
et al., 1998). Some studies are somewhere in be-                   Summary sentence: But it also raises the is-
tween: "summary language may or may not follow                     sue of privacy of such personal information
that of author's" (Fidel, 1986). Other guidelines or               and this issue hits the head on the nail in the
books on abstracting (ANSI, 1997; Cremmins, 1982)                  broader debate about privacy and security on
do not discuss the issue.                                          the internet.
  Our cut and paste based summarization is a com-
putational model; we make no claim that humans
                                                                  (3) syntactic transformation
                                                                  In both sentence reduction and combination, syn-
use the same cut and paste operations.
                                                                tactic transformations m a y be involved. For exam-
                                                                ple, the position of the subject in a sentence m a y be
2.2    Cut and paste operations                                 moved from the end to the front.
We manually analyzed 30 articles and their corre-                  (4) lexical paraphrasing
sponding human-written summaries; the articles and                 Replace phrases with their paraphrases. For in-
their summaries come from different domains ( 15                stance, the summaries substituted point out with
general news reports, 5 from the medical domain,                note, and fits squarely into with a more picturesque
10 from the legal domain) and the summaries were                description hits the head on the nail in the previous
written by professionals from different organizations.          examples.
We found that reusing article text for summarization              (5) g e n e r a l i z a t i o n o r specification
is almost universal in the corpus we studied. We de-
                                                                  Replace phrases or clauses with more general or
fined six operations that can be used alone, sequen-
                                                                specific descriptions. Examples of generalization
tially, or simultaneously to transform selected sen-            and specification include:
tences from an article into the corresponding sum-
mary sentences in its human-written abstract:
                                                                  Generalization:     "a proposed new law that
    (1) sentence reduction                                        would require Web publishers to obtain
   Remove extraneous phrases from a selected sen-                 parental consent before collecting personal in-
tence, as in the following example 1:                             formation from children" --+ "legislation to
                                                                  protect children's privacy on-line"
                                                                  Specification: "the White House's top drug
   1All the examples in this section were produced by human       official" ~ "Gen. Barry R. McCaffrey, the
professionals                                                      White House's top drug official"

                                                          179
                                                        Input~icle I . ~


                                                     I Sentenci extractiÂ°nl         )


                                                     extracteikey s e n t e n c ~

                     p . . . . .

                     ,_e_ yr _',              -
                                                   Cut and paste based generation
                 I
                 , Co-reference          ~,
                 I. . . . . . . . .      I
                                                     [ Sentence reduction ]
                     ,]WordNet'l
                                                     I Sentence combinatio~
              ~ned                 ie~        -~



                                                         Output summary

                                                    Figure 1: System architecture

   (6) r e o r d e r i n g                                               written abstracts, the automatic decomposition pro-
   Change the order of extracted sentences. For in-                      gram, a syntactic parser, a co-reference resolution
stance, place an ending sentence in an article at the                    system, the WordNet lexical database, and a large-
beginning of an abstract.                                                scale lexicon we combined from multiple resources.
   In human-written abstracts, there are, of course,                     The components in dotted lines are existing tools or
sentences that are not based on cut and paste, but                       resources; all the others were developed by ourselves.
completely written from scratch. We used our de-
composition program to automatically analyze 300                         4    Major components
human-written abstracts, and found that 19% of sen-                      The main focus of our work is on decomposition of
tences in the abstracts were written from scratch.                       summaries, sentence reduction, and sentence com-
There are also other cut and paste operations not                        bination. We also describe the sentence extraction
listed here due to their infrequent occurrence.                          module, although it is not the main focus of our
                                                                         work.

3    System     architecture                                             4.1    D e c o m p o s i t i o n of h u m a n - w r i t t e n
The architecture of our cut and paste based text                                summary sentences
summarization system is shown in Figure 1. Input                         The decomposition program, see (Jing and McKe-
to the system is a single document from any domain.                      own, 1999) for details, is used to analyze the con-
In the first stage, extraction, key sentences in the ar-                 struction of sentences in human-written abstracts.
ticle are identified, as in most current summarizers.                    The results from decomposition are used to build
In the second stage, cut and paste based generation, a                   the training and testing corpora for sentence reduc-
sentence reduction module and a sentence combina-                        tion and sentence combination.
tion module implement the operations we observed                            The decomposition program answers three ques-
in human-written abstracts.                                              tions about a sentence in a human-written abstract:
   The cut and paste based component receives as                         (1) Is the sentence constructed by cutting and past-
input not only the extracted key sentences, but also                     ing phrases from the input article? (2) If so, what
the original article. This component can be ported                       phrases in the sentence come from the original arti-
to other single-document summarizers to serve as                         cle? (3) Where in the article do these phrases come
the generation component, since most current sum-                        from?
marizers extract key sentences - exactly what the                           We used a Hidden Markov Model (Baum, 1972)
extraction module in our system does.                                    solution to the decomposition problem. We first
   Other resources and tools in the summarization                        mathematically formulated the problem, reducing it
system include a corpus of articles and their human-                     to a problem of finding, for each word in a summary

                                                                   180
      Summary sentence:
      (F0:S1 a r t h u r b s a c k l e r v i c e p r e s i d e n t for law a n d p u b l i c p o l i c y    o f t i m e w a r n e r inc )
      (FI:S-1 and) (F2:S0 a m e m b e r o f t h e d i r e c t m a r k e t i n g a s s o c i a t i o n      told ) (F3:$2 t h e c o m -
      munications subcommittee of the senate commerce committee )                                          (F4:S-1 that legislation )
      (F5:Slto p r o t e c t ) (F6:$4 c h i l d r e n ' s ) (F7:$4 p r i v a c y ) (F8:$4 o n l i n e      ) (F9:S0 could d e s t r o y
      the spontaneous nature that makes the internet unique )
      Source document sentences:
      Sentence 0: a proposed new law that would require web publishers to obtain parental consent before
      collecting personal information from children (F9 could d e s t r o y t h e s p o n t a n e o u s n a t u r e t h a t
      m a k e s t h e i n t e r n e t u n i q u e ) (F2 a m e m b e r of t h e d i r e c t m a r k e t i n g a s s o c i a t i o n told) a
      senate panel thursday
      Sentence 1 : ( F 0 a r t h u r b s a c k l e r v i c e p r e s i d e n t for law a n d p u b l i c p o l i c y o f t i m e w a r n e r
      inc ) said the association supported efforts (F5 to p r o t e c t ) children online but he urged lawmakers
      to find some middle ground that also allows for interactivity on the internet
      Sentence 2: for example a child's e-mail address is necessary in order to respond to inquiries such
      as updates on mark mcguire's and sammy sosa's home run figures this year or updates of an online
      magazine sackler said in testimony to (F3 t h e c o m m u n i c a t i o n s s u b c o m m i t t e e o f t h e s e n a t e
      commerce committee )
      Sentence 4: the subcommittee is considering the (F6 children's ) (F8 online ) (F7 p r i v a c y )
      protection act which was drafted on the recommendation of the federal trade commission

                                   Figure 2: Sample output of the decomposition p r o g r a m

sentence, a document position that it most likely                             reduction is to "reduce without m a j o r loss"; that is,
comes from. The position of a word in a document                              we want to remove as m a n y extraneous phrases as
is uniquely identified by the position of the sentence                        possible from an extracted sentence so that it can be
where the word appears, and the position of the word                          concise, but without detracting from the main idea
within the sentence. Based on the observation of cut                          that the sentence conveys. Ideally, we want to re-
and paste practice by humans, we produced a set of                            move a phrase from an extracted sentence only if it
general heuristic rules. Sample heuristic rules in-                            is irrelavant to the main topic.
clude: two adjacent words in a s u m m a r y sentence                            Our reduction module makes decisions based on
are most likely to come from two adjacent words in                            multiple sources of knowledge:
the original document; adjacent words in a s u m m a r y                         (1) G r a m m a r c h e c k i n g . In this step, we mark
sentence are not very likely to come from sentences                           which components of a sentence or a phrase are
that are far apart in the original document. We                               obligatory to keep it grammatically correct. To do
use these heuristic rules to create a Hidden Markov                           this, we traverse the sentence parse tree, produced
Model. The Viterbi algorithm (Viterbi, 1967) is used                          by the English Slot G r a m m a r ( E S G ) parser devel-
to efficiently find the most likely document position                         oped at IBM (McCord, 1990), in top-down order
for each word in the s u m m a r y sentence.                                  and m a r k for each node in the parse tree, which
   Figure 2 shows sample output of the program.                               of its children are obligatory. The main source of
For the given s u m m a r y sentence, the program cor-                        knowledge the system relies on in this step is a
rectly identified that the sentence was combined                              large-scale, reusable lexicon we combined from mul-
from four sentences in the input article. It also di-                         tiple resources (Jing and McKeown, 1998). The lexi-
vided the s u m m a r y sentence into phrases and pin-                        con contains subcategorizations for over 5,000 verbs.
pointed the exact document origin of each phrase.                             This information is used to m a r k the obligatory ar-
A phrase in the s u m m a r y sentence is annotated as                        guments of verb phrases.
(FNUM:SNUM actual-text), where F N U M is the se-                                (2) C o n t e x t i n f o r m a t i o n . We use an extracted
quential number of the phrase and S N U M is the                              sentence's local context in the article to decide which
number of the document sentence where the phrase                              components in the sentence are likely to be most
comes from. SNUM = -1 means that the compo-                                   relevant to the main topic. We link the words in the
nent does not come from the original document. The                            extracted sentence with words in its local context,
phrases in the document sentences are annotated as                            if they are repetitions, morphologically related, or
(FNUM actual-text).                                                           linked with each other in WordNet through certain
                                                                              type of lexical relation, such as synonymy, antonymy,
4.2   Sentence reduction                                                      or meronymy. Each word in the extracted sentence
The task of the sentence reduction module, de-                                gets an importance score, based on the number of
scribed in detail in (Jing, 2000), is to remove extra-                        links it has with other words and the types of links.
neous phrases from extracted sentences. The goal of                           Each phrase in the sentence is then assigned a score

                                                                        181
        E x a m p l e 1:
        Original sentence : When it arrives sometime next year in new T V sets, t h e V - c h i p will give
        parents a new and potentially revolutionary device to block out programs t h e y don't
        w a n t their children to see.
        Reduction program: The V-chip will give parents a new and potentially revolutionary device to
        block out programs they don't want their children to see.
        Professionals        : The V-chip will give parents a device to block out programs they don't want
        their children to see.

        E x a m p l e 2:
        Original sentence : Sore a n d H o f f m a n ' s creation would allow broadcasters to insert
        m u l t i p l e ratings into a show, enabling the V-chip to filter out racy or violent material but leave
        unexceptional portions o.f a show alone.
       Reduction Program: Som and Hoffman's creation would allow broadcasters to insert multiple rat-
       ings into a show.
       Professionals     : Som and Hoffman's creation would allow broadcasters to insert multiple rat-
       ings into a show.

                              Figure 3: Sample output of the sentence reduction p r o g r a m

by adding up the scores of its children nodes in the                   4.3   Sentence combination
parse tree. This score indicates how i m p o r t a n t the             To build the combination module, we first manu-
phrase is to the main topic in discussion.                             ally analyzed a corpus of combination examples pro-
   (3) C o r p u s e v i d e n c e . The p r o g r a m uses a cor-     duced by h u m a n professionals, automatically cre-
pus of input articles and their corresponding reduced                  ated by the decomposition program, and identified
forms in human-written abstracts to learn which                        a list of combination operations. Table 1 shows the
components of a sentence or a phrase can be re-                        combination operations.
moved and how likely they are to be removed by                            To implement a combination operation, we need
professionals. This corpus was created using the de-                   to do two things: decide when to use which com-
composition program. We compute three types of                         bination operation, and implement the combining
probabilities from this corpus: the probability t h a t                actions. To decide when to use which operation, we
a phrase is removed; the probability t h a t a phrase is               analyzed examples by humans and manually wrote
reduced (i.e., the phrase is not removed as a whole,                   a set of rules. Two simple rules are shown in Fig-
but some components in the phrase are removed);                        ure 4. Sample outputs using these two simple rules
and the probability that a phrase is unchanged at                      are shown in Figure 5. We are currently exploring
all (i.e., neither removed nor reduced). These cor-                    using machine learning techniques to learn the com-
pus probabilities help us capture h u m a n practice.                  bination rules from our corpus.
   (4) F i n a l d e c i s i o n . The final reduction decision           The implementation of the combining actions in-
is based on the results from all the earlier steps. A                  volves joining two parse trees, substituting a subtree
phrase is removed only if it is not grammatically                      with another, or adding additional nodes. We im-
obligatory, not the focus of the local context (indi-                  plemented these actions using a formalism based on
cated by a low context importance score), and has a                    Tree Adjoining G r a m m a r (Joshi, 1987).
reasonable probability of being removed by humans.
The phrases we remove from an extracted sentence                       4.4   Extraction Module
include clauses, prepositional phrases, gerunds, and                   The extraction module is the front end of the sum-
to-infinitives.                                                        marization system and its role is to extract key sen-
   The result of sentence reduction is a shortened                     tences. Our method is primarily based on lexical re-
version of an extracted sentence 2. This shortened                     lations. First, we link words in a sentence with other
text can be used directly as a s u m m a r y , or it can               words in the article through repetitions, morpholog-
be fed to the sentence combination module to be                        ical relations, or one of the lexical relations encoded
merged with other sentences.                                           in WordNet, similar to step 2 in sentence reduction.
   Figure 3 shows two examples produced by the re-                     An importance score is computed for each word in a
duction program. The corresponding sentences in                        sentence based on the number of lexical links it has
human-written abstracts are also provided for com-                     with other words, the type of links, and the direc-
parison.                                                               tions of the links.
   2It is actually also possible that the reduction program               After assigning a score to each word in a sentence,
decides no phrase in a sentence should be removed, thus the            we then compute a score for a sentence by adding up
result of reduction is the same as the input.                          the scores for each word. This score is then normal-

                                                                 182
    Categories                                                       Combination Operations
    Add descriptions or names for people or organizations            add description (see Figure 5)
                                                                     add name
    Aggregations                                                     extract common subjects or objects (see Figure 5)
                                                                     change one sentence to a clause
                                                                     add connectives (e.g., and or while)
                                                                     add punctuations (e.g., ";")
    Substitute incoherent phrases                                    substitute dangling anaphora
                                                                     substitute dangling noun phrases
                                                                     substitute adverbs (e.g., here)
                                                                     remove connectives
    Substitute phrases with more general or specific information     substitute with more general information
                                                                     substitute with more specific information
    Mixed operations                                                 combination of any of above operations (see Figure 2)


                                           Table 1: Combination operations

         Rule 1:
         IF: ((a person or an organization is mentioned the first time) and (the full name or the full descrip-
         tion of the person or the organization exists somewhere in the original article but is missing in the
         summary))
         T H E N " replace the phrase with the full name plus the full description
         Rule 2:
         IF: ((two sentences are close to each other in the original article) and (their subjects refer to the
         same entity) and (at least one of the sentences is the reduced form resulting from sentence reduc-
         tion))
         T H E N : merge the two sentences by removing the subject in the second sentence, and then com-
         bining it with the first sentence using connective "and".

                                    Figure 4: Sample sentence combination rules

ized over the number of words a sentence contains.              in the abstracts. We compared the set of sentences
The sentences with high scores are considered im-               identified by the p r o g r a m with the set of sentences
portant.                                                        selected by the m a j o r i t y of h u m a n subjects, which is
   The extraction system selects sentences based on             used as the gold standard in the computation of pre-
the importance computed as above, as well as other              cision and recall. The program achieved an average
indicators, including sentence positions, cue phrases,          81.5% precision, 78.5% recall, and 79.1% f-measure
and tf*idf scores.                                              for 10 documents. The average performance of 14
                                                                h u m a n judges is 88.8% precision, 84.4% recall, and
5      Evaluation                                               85.7% f-measure. Recently, we have also tested the
                                                                system on legal documents (the headnotes used by
Our evaluation includes separate evaluations of each            Westlaw company), and the p r o g r a m works well on
module and the final evaluations of the overall sys-            those documents too.
tem.
   We evaluated the decomposition program by two                   The evaluation of sentence reduction (see (Jing,
experiments, described in (Jing and McKeown,                    2000) for details) used a corpus of 500 sentences and
 1999).   In the first experiment, we selected 50               their reduced forms in human-written abstracts. 400
human-written abstracts, consisting of 305 sentences            sentences were used to compute corpus probabili-
in total. A h u m a n subject then read the decomposi-          ties and 100 sentences were used for testing. The
tion results of these sentences to judge whether they           results show that 81.3% of the reduction decisions
are correct. 93.8% of the sentences were correctly              made by the system agreed with those of humans.
decomposed. In the second experiment, we tested                 The humans reduced the length of the 500 sentences
the system in a s u m m a r y alignment task. We ran            by 44.2% on average, and the system reduced the
the decomposition program to identify the source                length of the 100 test sentences by 32.7%.
document sentences that were used to construct the                 The evaluation of sentence combination module
sentences in human-written abstracts. H u m a n sub-            is not as straightforward as that of decomposition
jects were also asked to select the document sen-               or reduction since combination happens later in the
tences that are semantlc-equivalent to the sentences            pipeline and it depends on the output from prior

                                                          183
      E x a m p l e 1: a d d d e s c r i p t i o n s or n a m e s for people or o r g a n i z a t i o n
      Original document sentences:
       "We're trying to prove that there are big benefits to the patients by involving them more deeply in
      their treatment", said Paul Clayton, C h a i r m a n o f t h e D e p a r t m e n t d e a l i n g with c o m p u t -
      erized m e d i c a l i n f o r m a t i o n at Columbia.
      " T h e e c o n o m i c p a y o f f f r o m breaking into health care records is a lot less t h a n for
      b a n k s " , said Clayton at Columbia.
      Combined sentence:
      "The economic payoff from breaking into health care records is a lot less than for banks", said Paul
      Clayton, Chairman of the Department dealing with computerized medical information at Columbia.
      Professional: (the same)

      E x a m p l e 2: e x t r a c t c o m m o n s u b j e c t s
      Original document sentences:
      T h e n e w m e a s u r e is a n e c h o o f t h e original b a d idea, blurred just enough to cloud prospects
      both for enforcement and for court review.
      Unlike the 1996 act, this o n e a p p l i e s o n l y t o c o m m e r c i a l W e b s i t e s - thus sidestepping
      1996 objections to the burden such regulations would pose for museums, libraries and freewheeling
      conversation deemed "indecent" by somebody somewhere.
      T h e n e w v e r s i o n also r e p l a c e s t h e v a g u e " i n d e c e n c y " s t a n d a r d , to which the court objected,
      with the better-defined one of material ruled "harmful to minors."
      Combined sentences:
      The new measure is an echo of the original bad idea.
      The new version applies only to commercial web sites and replaces the vague "indecency" standard
      with the better-defined one of material ruled "harmful to minors."
      Professional:
      While the new law replaces the "indecency" standard with "harmful to minors" and now only
      applies to commercial Web sites, the "new measure is an echo of the original bad idea."

                             Figure 5: Sample output of the sentence combination program


modules. To evaluate just the combination compo-                            They were also asked to score the coherence of the
nent, we assume that the system makes the same                              summaries based on a scale from 0 to 10. On aver-
reduction decision as humans and the co-reference                           age, the extraction-based summaries have a score of
system has a perfect performance. This involves                             4.2 for conciseness, while the revised summaries have
manual tagging of some examples to prepare for the                          a score of 7.9 (an improvement of 88%). The average
evaluation; this preparation is in progress. The eval-                      improvement for the three systems are 78%, 105%,
uation of sentence combination will focus on the ac-                        and 88% respectively. The revised summaries are
cessment of combination rules.                                              on average 41% shorter than the original extraction-
   The overM1 system evMuation includes both in-                            based summaries. For s u m m a r y coherence, the aver-
trinsic and extrinsic evaluation. In the intrinsic evM-                     age score for the extraction-based summaries is 3.9,
uation, we asked human subjects to compare the                              while the average score for the revised summaries is
quality of extraction-based summaries and their re-                         6.1 (an improvement of 56%). The average improve-
vised versions produced by our sentence reduction                           ment for the three systems are 69%, 57%, and 53%
and combination modules. We selected 20 docu-                               respectively.
ments; three different automatic summarizers were                              We are preparing a task-based evaluation, in
used to generate a summary for each document, pro-                          which we will use the data from the Summariza-
ducing 60 summaries in total. These summaries                               tion EvMuation Conference (Mani et al., 1998) and
are all extraction-based. We then ran our sentence                          compare how our revised summaries can influence
reduction and sentence combination system to re-                            humans' performance in tasks like text categoriza-
vise the summaries, producing a revised version for                         tion and ad-hoc retrieval.
each summary. We presented human subjects with
the full documents, the extraction-based summaries,                          6     Related         work
and their revised versions, and asked them to com-
pare the extraction-based summaries and their re-                            (Mani et al., 1999) addressed the problem of revising
vised versions. The human subjects were asked to                            summaries to improve their quality. They suggested
score the conciseness of the summaries (extraction-                         three types of operations: elimination, aggregation,
based or revised) based on a scale from 0 to 10 -                           and smoothing. The goal of the elimination opera-
the higher the score, the more concise a summary is.                        tion is similar to that of the sentence reduction op-

                                                                      184
eration in our system. The difference is that while         probabilistic functions of a markov process. In-
elimination always removes parentheticals, sentence-        equalities, (3):1-8.
initial PPs and certain adverbial phrases for every       Edward T. Cremmins. 1982. The Art of Abstracting.
extracted sentence, our sentence reduction module           ISI Press, Philadelphia.
aims to make reduction decisions according to each        Brigitte Endres-Niggemeyer, Kai Haseloh, Jens
case and removes a sentence component only if it            Mfiller, Simone Peist, Irene Santini de Sigel,
considers it appropriate to do so. The goal of the          Alexander Sigel, Elisabeth Wansorra, Jan
aggregation operation and the smoothing operation           Wheeler, and Brfinja Wollny. 1998. Summarizing
is similar to that of the sentence combination op-          Information. Springer, Berlin.
eration in our system. However, the combination           Raya Fidel. 1986. Writing abstracts for free-text
operations and combination rules that we derived            searching. Journal of Documentation, 42(1):11-
from corpus analysis are significantly different from       21, March.
those used in the above system, which mostly came         Hongyan Jing and Kathleen R. McKeown. 1998.
from operations in traditional natural language gen-        Combining multiple, large-scale resources in a
eration.                                                    reusable lexicon for natural language generation.
                                                            In Proceedings of the 36th Annual Meeting of the
7   Conclusions and future w o r k                          Association for Computational Linguistics and the
This paper presents a novel architecture for text           17th International Conference on Computational
summarization using cut and paste techniques ob-            Linguistics, volume 1, pages 607-613, Universit6
served in human-written abstracts. In order to auto-        de Montreal, Quebec, Canada, August.
matically analyze a large quantity of human-written       Hongyan Jing and Kathleen R. McKeown. 1999.
abstracts, we developed a decomposition program.            The decomposition of human-written summary
The automatic decomposition allows us to build              sentences. In Proceedings of the P2nd In-
large corpora for studying sentence reduction and           ternational ACM SIGIR Conference on Re-
sentence combination, which are two effective op-           search and Development in Information Re-
erations in cut and paste. We developed a sentence          trieval(SIGIR'99), pages 129-136, University of
reduction module that makes reduction decisions us-         Berkeley, CA, August.
ing multiple sources of knowledge. We also investi-       Hongyan Jing. 2000. Sentence reduction for au-
gated possible sentence combination operations and          tomatic text summarization. In Proceedings of
implemented the combination module. A sentence              ANLP 2000.
extraction module was developed and used as the           Aravind.K. Joshi. 1987. Introduction to tree-
front end of the summarization system.                      adjoining grammars. In A. Manaster-Ramis, ed-
   We are preparing the task-based evaluation of the        itor, Mathematics of Language. John Benjamins,
overall system. We also plan to evaluate the porta-         Amsterdam.
bility of the system by testing it on another corpus.     Inderjeet Mani, David House, Gary Klein, Lynette
We will also extend the system to query-based sum-          Hirschman, Leo Obrst, Therese Firmin, Michael
marization and investigate whether the system can           Chrzanowski, and Beth Sundheim. 1998. The
be modified for multiple document summarization.            TIPSTER SUMMAC text summarization eval-
                                                            uation final report. Technical Report MTR
Acknowledgment                                              98W0000138, The MITRE Corporation.
                                                          Inderjeet Mani, Barbara Gates, and Erie Bloedorn.
We thank IBM for licensing us the ESG parser                1999. Improving summaries by revising them. In
and the MITRE corporation for licensing us the co-          Proceedings of the 37th Annual Meeting of the As-
reference resolution system. This material is based         sociation for Computational Linguistics(A CL '99),
upon work supported by the National Science Foun-           pages 558-565, University of Maryland, Mary-
dation under Grant No. IRI 96-19124 and IRI                 land, June.
96-18797. Any opinions, findings, and conclusions         Michael MeCord, 1990. English Slot Grammar.
or recommendations expressed in this material are           IBM.
those of the authors and do not necessarily reflect       Samuel Thurber, editor. 1924. Prgcis Writing for
the views of the National Science Foundation.               American Schools. The Atlantic Monthly Press,
                                                            INC., Boston.
References                                                A.J. Viterbi. 1967. Error bounds for convolution
ANSI. 1997. Guidelines for abstracts. Technical Re-         codes and an asymptotically optimal decoding al-
  port Z39.14-1997, NISO Press, Bethesda, Mary-             gorithm. IEEE Transactions on Information The-
  land.                                                      ory, 13:260-269.
L. Baum. 1972. An inequality and associated max-
  imization technique in statistical estimation of

                                                    185
