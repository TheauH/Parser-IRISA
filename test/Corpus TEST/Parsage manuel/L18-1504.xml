<article>
    <preamble>L18-1504.pdf</preamble>
    <titre>A New Annotated Portuguese/Spanish Corpus for the Multi-Sentence Compression Task</titre>
    <auteurs>
        <auteur>Elvys Linhares Pontes (elvys.linhares-pontes@univ-avignon.fr</auteur>
        <affiliation>CERI/LIA, Universit´e d’Avignon et des Pays de Vaucluse, Avignon, France</affiliation>
        <auteur>Juan-Manuel Torres-Moreno (juan-manuel.torres@univ-avignon.fr)</auteur>
        <affiliation>CERI/LIA, Universit´e d’Avignon et des Pays de Vaucluse, Avignon, France
´Ecole Polytechnique de Montr´eal, Montr´eal, Canada</affiliation>
        <auteur>St´ephane Huet (stephane.huet@univ-avignon.fr)</auteur>
        <affiliation>CERI/LIA, Universit´e d’Avignon et des Pays de Vaucluse, Avignon, France</affiliation>
        <auteur>Andr´ea Carneiro Linhares (andrea.linhares@ufc.br)</auteur>
        <affiliation>Universidade Federal do Cear´a, Sobral-CE, Brasil</affiliation>
    </auteurs>
    <abstract>Abstract
Multi-sentence compression aims to generate a short and informative compression from several source sentences that deal with the same
topic. In this work, we present a new corpus for the Multi-Sentence Compression (MSC) task in Portuguese and Spanish. We also
provide on this corpus a comparison of two state-of-the-art MSC systems.
Keywords: Annotated Corpus, Multi-Sentence Compression, Multilingual Corpus.</abstract>
    <introduction>1.
Introduction
Among the various applications of Natural Language Pro-
cessing, Automatic Text Summarization (ATS) aims at
summarizing one or more texts automatically. Summariza-
tion systems identify relevant data and create a summary
from key information. The (Multi-)Sentence Compression
task can be seen as a subproblem of ATS with the objective
to generate a shorter, informative and correct sentence from
source sentence(s).
In many cases, state-of-the-art NLP systems are evaluated
with experiments restrained to the English language, in part
because there are a lot of available English resources for
most NLP tasks. As regards Multi-Sentence Compression
(MSC), the available resources are unfortunately limited; to
our knowledge, only one dataset is freely available and it is
confined to the French language (Boudin and Morin, 2013).
In this work, we present a new annotated corpus in the Por-
tuguese and Spanish languages for the MSC task. Using
this corpus, we evaluate two state-of-the-art systems and
show that the use of several languages leads to more miti-
gated results on the superiority of one system than the use
of the French corpus alone.
The remainder of this paper is organized as follows. In Sec-
tion 2, we characterize MSC with respect to related tasks
from the perspective of the available corpora. Section 3
describes the creation and the features of our corpus. In
Section 4 we analyze the results achieved by state-of-the-
art methods using our dataset. Finally, conclusions are set
out in Section 5.</introduction>
    <results>4.2. Results with Automatic Metrics
Table 3 shows f-score ROUGE scores for the French, Por- tuguese and Spanish datasets.8 Boudin and Morin’s system generated better compressions with higher ROUGE scores than Filippova’s and the baseline for all datasets.
6Website: http://www.florianboudin.org/ publications.html
7 http://snowball.tartarus.org/
8Although we used the same system and data as (Boudin and Morin, 2013) for the French corpus, we were not able to repro- duce exactly their results. The ROUGE scores given in their arti- cle are close to ours for their system: 0.6568 (ROUGE-1), 0.4414 (ROUGE-2) and 0.4344 (ROUGE-SU4), but using Filippova’s system we measured higher scores than them: 0.5744 (ROUGE- 1), 0.3921 (ROUGE-2) and 0.3700 (ROUGE-SU4).
 3194
 French RG-1 RG-2
Table 4 provides statistics on the length and the compres- sion ratio of the sentences generated by the systems. The baseline system output the shortest compressions, which translated into the worst ROUGE scores. For the three tested datasets, Filippova’s method generated shorter com- pressions with a smaller standard deviation than Boudin and Morin’s system. Let us note that for this last system the lengths of the outputs are less regular across the three languages.
The Portuguese and Spanish languages derive from Latin and are closely related languages. However, they differ in many details of their grammar and lexicon. Moreover, the datasets produced for the three languages are unlike accord- ing to several features. First, our corpus contains a smaller (Portuguese corpus) and a larger (Spanish corpus) dataset in terms of sentences than the original French corpus. Be- sides, the compression rates of the three datasets (see Sec- tion 3.) indicates that the Portuguese source sentences have more irrelevant tokens. The sentence similarity (Table 1, last line) describes the variability of sentences in the source sentences and in the references, and reflects here that the sentences are slightly more diverse for the Portuguese cor- pus. It can be noticed that the references are more similar too each other than source sentences since they only retain the main information. Finally, the French corpus has a TTR of 38.8% whereas the Portuguese and Spanish datasets have TTRs of 33.7% and 35.2%, respectively.
The baseline system generated the shortest compression be- cause all arcs of the WG have the same weights. However, this system analyzes neither the grammaticality nor the most used n-grams in the clusters. Consequently, the base- line system generated compressions with the worst ROUGE scores.</results>
    <conclusion>5.
Conclusion and Future Work
Multi-Sentence Compression aims to generate a short infor-
mative text summary from several sentences with related
and redundant information. This task can be used in the
domain of multi-document summarization or question an-
swering to provide more informative and concise texts.
In this paper, we presented a new annotated corpus in
two languages that extends the French data made available
in (Boudin and Morin, 2013). We also compared two state-
of-the art systems on this new dataset. We hope this cor-
pus will help the NLP community to develop and validate
multi-language methods for multi-sentence compression.
In order to extend the multi-language resources to more di-
verse languages, we plan to create a similar MSC dataset
for Arabic. We also want to use our corpus to test other
competitive MSC systems, such as the one based on integer
linear programming we introduced in (Linhares Pontes et
al., 2016).</conclusion>
    <biblio>7.
Bibliographical References
Barzilay, R. and McKeown, K. R. (2005). Sentence fusion
for multidocument news summarization. Computational
Linguistics, 31(3):297–328, September.
Boudin, F. and Morin, E. (2013). Keyphrase extraction
for N-best reranking in multi-sentence compression. In
NAACL, pages 298–305.
Clarke, J. and Lapata, M. (2008). Global inference for
sentence compression: An integer linear programming
approach.
Journal of Artificial Intelligence Research
(JAIR, 31:399–429.
Cohn, T. and Lapata, M. (2008). Sentence compression
beyond word deletion. In COLING, pages 137–144.
Filippova, K. and Altun, Y. (2013). Overcoming the lack of
parallel data in sentence compression. In EMNLP, pages
1481–1491.
Filippova, K., Alfonseca, E., Colmenares, C. A., Kaiser,
L., and Vinyals, O. (2015). Sentence compression by
deletion with LSTMs. In EMNLP, pages 360–368.
Filippova, K. (2010). Multi-sentence compression: Find-
ing shortest paths in word graphs. In COLING, pages
322–330.
Ganitkevitch, J., Callison-Burch, C., Napoles, C., and
Durme, B. V. (2011). Learning sentential paraphrases
from bilingual parallel corpora for text-to-text genera-
tion. In EMNLP, pages 1168–1179.
Ive, J. and Yvon, F. (2016). Parallel sentence compression.
In COLING, Technical Papers, page 1503–1513.
Knight, K. and Marcu, D. (2002). Summarization beyond
sentence extraction: A probabilistic approach to sentence
compression. Artificial Intelligence, 139(1):91–107.
Lin, C.-Y. (2004). ROUGE: A Package for Automatic
Evaluation of Summaries. In Workshop Text Summariza-
tion Branches Out (ACL’04), pages 74–81.
Linhares Pontes, E., Gouveia da Silva, T., Linhares,
A. C., Torres-Moreno, J.-M., and Huet, S.
(2016).
M´etodos de otimizac¸˜ao combinat´oria aplicados ao prob-
lema de compress˜ao multifrases. In Anais do XLVIII
Simp´osio Brasileiro de Pesquisa Operacional (SBPO),
pages 2278–2289.
Luong, A. V., Tran, N. T., Ung, V. G., and Nghiem, M. Q.
(2015). Word graph-based multi-sentence compression:
Re-ranking candidates using frequent words. In Sev-
enth International Conference on Knowledge and Sys-
tems Engineering (KSE), pages 55–60.
McKeown, K., Rosenthal, S., Thadani, K., and Moore, C.
(2010). Time-efficient creation of an accurate sentence
fusion corpus. In HLT-NAACL, pages 317–320.
Rush, A. M., Chopra, S., and Weston, J. (2015). A neural
attention model for abstractive sentence summarization.
In EMNLP, pages 379–389.
Thadani, K. and McKeown, K. (2013). Supervised sen-
tence fusion with single-stage inference. In Sixth Inter-
national Joint Conference on Natural Language Process-
ing, IJCNLP, pages 1410–1418.
Toutanova, K., Brockett, C., Tran, K. M., and Amershi,
S. (2016). A dataset and evaluation metrics for abstrac-
tive compression of sentences and short paragraphs. In
EMNLP, pages 340–350.
8.
Language Resource References
Boudin,
Florian
and
Morin,
Emmanuel.
(2013).
Keyphrase Extraction for N-best Reranking in Multi-
Sentence Compression. NAACL (2013). Available on
https://github.com/boudinfl/lina-msc.
Graff, David and Cieri, Christopher and Kong, Junbo and
Chen, Ke and Maeda, Kazuaki. (2011). English Gi-
gaword. Linguistic Data Consortium, 5th, ISLRN 911-
942-430-413-0.</biblio>
</article>