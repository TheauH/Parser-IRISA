<article>
    <preamble>acl2012.pdf</preamble>
    <titre>Finding Salient Dates for Building Thematic Timelines</titre>
    <auteurs>
        <auteur>Rémy Kessler (kessler@limsi.fr)</auteur>
        <affiliation>LIMSI-CNRS
Orsay, France</affiliation>
        <auteur>Xavier Tannier (xtannier@limsi.fr)</auteur>
        <affiliation>Univ. Paris-Sud,
LIMSI-CNRS
Orsay, France</affiliation>
        <auteur>Caroline Hagège (hagege@xrce.xerox.com)</auteur>
        <affiliation>Xerox Research Center Europe
Meylan, France</affiliation>
        <auteur>Véronique Moriceau (moriceau@limsi.fr)</auteur>
        <affiliation>Univ. Paris-Sud, LIMSI-CNRS
Orsay, France</affiliation>
        <auteur>André Bittar (bittar@xrce.xerox.com)</auteur>
        <affiliation>Xerox Research Center Europe
Meylan, France</affiliation>
    </auteurs>
    <abstract>We present an approach for detecting salient
(important) dates in texts in order to auto-
matically build event timelines from a search
query (e.g. the name of an event or person,
etc.). This work was carried out on a corpus
of newswire texts in English provided by the
Agence France Presse (AFP). In order to ex-
tract salient dates that warrant inclusion in an
event timeline, we first recognize and normal-
ize temporal expressions in texts and then use
a machine-learning approach to extract salient
dates that relate to a particular topic. We fo-
cused only on extracting the dates and not the
events to which they are related.</abstract>
    <introduction>Our aim here was to build thematic timelines for
a general domain topic defined by a user query.
This task, which involves the extraction of important
events, is related to the tasks of Retrospective Event
Detection (Yang et al., 1998), or New Event Detec-
tion, as defined for example in Topic Detection and
Tracking (TDT) campaigns (Allan, 2002).
The majority of systems designed to tackle this
task make use of textual information in a bag-of-
words manner.
They use little temporal informa-
tion, generally only using document metadata, such
as the document creation time (DCT). The few sys-
tems that do make use of temporal information (such
as the now discontinued Google timeline), only ex-
tract absolute, full dates (that feature a day, month
and year). In our corpus, described in Section 3.1,
we found that only 7% of extracted temporal expres-
sions are absolute dates.
We distinguish our work from that of previous re-
searchers in that we have focused primarily on ex-
tracted temporal information as opposed to other
textual content. We show that using linguistic tem-
poral processing helps extract important events in
texts. Our system extracts a maximum of temporal
information and uses only this information to detect
salient dates for the construction of event timelines.
Other types of content are used for initial thematic
document retrieval. Output is a list of dates, ranked
from most important to least important with respect
to the given topic. Each date is presented with a set
of relevant sentences.
We can see this work as a new, easily evaluable
task of “date extraction”, which is an important com-
ponent of timeline summarization.
In what follows, we first review some of the re-
lated work in Section 2. Section 3 presents the re-
sources used and gives an overview of the system.
The system used for temporal analysis is described
in Section 4, and the strategy used for indexing and
finding salient dates, as well as the results obtained,
are given in Section 51.
1This work has been partially funded by French National
Research Agency (ANR) under project Chronolines (ANR-10-
CORD-010). We would like to thank the French News Agency
(AFP) for providing us with the corpus.</introduction>
    <corps>2
Related Work
The ISO-TimeML language (Pustejovsky et al.,
2010) is a specification language for manual anno-
tation of temporal information in texts, but, to the
best of our knowledge, it has not yet actually been
used in information retrieval systems.
Neverthe-
less, (Alonso et al., 2007; Alonso, 2008; Kanhabua,
2009) and (Mestl et al., 2009), among others, have
highlighted that the analysis of temporal informa-
tion is often an essential component in text under-
standing and is useful in a wide range of informa-
tion retrieval applications. (Harabagiu and Bejan,
2005; Saquete et al., 2009) highlight the importance
of processing temporal expressions in Question An-
swering systems. For example, in the TREC-10 QA
evaluation campaign, more than 10% of questions
required an element of temporal processing in order
to be correctly processed (Li et al., 2005a). In multi-
document summarization, temporal processing en-
ables a system to detect redundant excerpts from
various texts on the same topic and to present re-
sults in a relevant chronological order (Barzilay and
Elhadad, 2002). Temporal processing is also useful
for aiding medical decision-making. (Kim and Choi,
2011) present work on the extraction of temporal in-
formation in clinical narrative texts. Similarly, (Jung
et al., 2011) present an end-to-end system that pro-
cesses clinical records, detects events and constructs
timelines of patients’ medical histories.
The various editions of the TDT task have given
rise to the development of different systems that de-
tect novelty in news streams (Allan, 2002; Kumaran
and Allen, 2004; Fung et al., 2005). Most of these
systems are based on statistical bag-of-words mod-
els that use similarity measures to determine prox-
imity between documents (Li et al., 2005b; Brants
et al., 2003). (Smith, 2002) used spatio-temporal in-
formation from texts to detect events from a digital
library. His method used place/time collocations and
ranked events according to statistical measures.
Some efforts have been made for automatically
building textual and graphical timelines.
For ex-
ample, (Allan et al., 2001) present a system that
uses measures of pertinence and novelty to con-
struct timelines that consist of one sentence per date.
(Chieu and Lee, 2004) propose a similar system that
extracts events relevant to a query from a collection
of documents. Important events are those reported
in a large number of news articles and each event is
constructed according to one single query and rep-
resented by a set of sentences. (Swan and Allen,
2000) present an approach to generating graphical
timelines that involves extracting clusters of noun
phrases and named entities. More recently, (Yan et
al., 2011b; Yan et al., 2011a) used a summarization-
based approach to automatically generate timelines,
taking into account the evolutionary characteristics
of news.
3
Resources and System Overview
3.1
AFP Corpus
For this work, we used a corpus of newswire texts
provided by the AFP French news agency. The En-
glish AFP corpus is composed of 1.3 million texts
that span the 2004-2011 period (511 documents/day
in average and 426 millions words). Each document
is an XML file containing a title, a date of creation
(DCT), set of keywords, and textual content split
into paragraphs.
3.2
AFP Chronologies
AFP “chronologies” (textual event timelines) are a
specific type of articles written by AFP journal-
ists in order to contextualize current events. These
chronologies may concern any topic discussed in the
media, and consist in a list of dates (typically be-
tween 10 and 20) associated with a text describing
the related event(s). Figure 1 shows an example of
such a chronology. Further examples are given in
Figure 2. We selected 91 chronologies satisfying the
following constraints:
• All dates in the chronologies are between 2004
and 2011 to be sure that the related events
are described in the corpus.
For example,
“Chronology of climax to Vietnam War” was
excluded because its corresponding dates do
not appear in the content of the articles.
• All dates in the chronology are anterior to the
chronology’s creation date. For example, the
chronology “Space in 2005: A calendar”, pub-
lished in January 2005 and listing scheduled
events, was not selected (because almost no
rocket launches finally happened on the ex-
pected day).
• The temporal granularity of the chronology is
the day. For example, “A timeline of how the
London transport attacks unfolded”, relating
the events hour by hour, is not in our focus.
&lt;NewsML Version="1.2"&gt;
&lt;NewsItem xml:lang="en"&gt;
&lt;HeadLine&gt;Key
dates
in
Thai-
land’s
political
crisis&lt;/HeadLine&gt;
&lt;DateId&gt;20100513T100519Z&lt;/DateId&gt;
&lt;NameLabel&gt;Thailand-politics&lt;/NameLabel&gt;
&lt;DataContent&gt;
&lt;p&gt;The following is a timeline of events since
the protests began, soon after Thailand’s Supreme
Court confiscated 1.4 billion dollars of Thaksin’s
wealth for abuse of power.&lt;/p&gt;
&lt;p&gt;March 14: Tens of thousands of Red Shirts
demonstrate in the capital calling for Abhisit’s gov-
ernment to step down, [...]&lt;/p&gt;
&lt;p&gt;March 28: The government and the Reds en-
ter into talks but hit a stalemate after two days
[...]&lt;/p&gt;
&lt;p&gt;April 3: Tens of thousands of protesters move
from Bangkok’s historic district into the city’s com-
mercial heart [...]&lt;/p&gt;
&lt;p&gt;April 7: Abhisit declares state of emergency
in capital after Red Shirts storm parliament.&lt;/p&gt;
&lt;p&gt;April 8: Authorities announce arrest warrants
for protest leaders.&lt;/p&gt;
. . .
&lt;/DataContent&gt;
&lt;/NewsItem&gt;
&lt;/NewsML&gt;
Figure 1: Example of an AFP manual chronology.
For
learning
and
evaluation
purposes,
all
chronologies were converted to a single XML
format.
Each document was manually associated
with a user search query made up of the keywords
required to retrieve the chronology.
3.3
System Overview
Figure 3 shows the general architecture of the sys-
tem. First, pre-processing of the AFP corpus tags
and normalizes temporal expressions in each of the
articles (step x in the Figure). Next, the corpus is
indexed by the Lucene search engine2 (step y).
Given a query, a number of documents are re-
trieved by Lucene (z). These documents can be fil-
tered ({), and dates are extracted from the remain-
ing documents. These dates are then ranked in order
to show the most important ones to the user (|), to-
2http://lucene.apache.org
- Chronology of 18 months of trouble in Ivory Coast
- Chechen rebels’ history of hostage-takings
- Iraqi political wrangling since March 7 election
- Athletics: Timeline of men’s 800m world record
- Major accidents in Chinese mines
- Space in 2005: A calendar
- Developments in Iranian nuclear standoff
- Chronology of climax to Vietnam War
- Timeline of ex-IMF chief’s sex attack case
- A timeline of how the London transport attacks un-
folded
Figure 2: Examples of AFP chronologies.
Figure 3: System overview.
gether with the sentences that contain them.
4
Temporal and Linguistic Processing
In this section, we describe the linguistic and tempo-
ral information extracted during the pre-processing
phase and how the extraction is carried out.
We
rely on the powerful linguistic analyzer XIP (A¨ıt-
Mokhtar et al., 2002), that we adapted for our pur-
poses.
4.1
XIP
The linguistic analyzer we use performs a deep syn-
tactic analysis of running text.
It takes as input
XML files and analyzes the textual content enclosed
in the various XML tags in different ways that are
specified in an XML guide (a file providing instruc-
tions to the parser, see (Roux, 2004) for details).
XIP performs complete linguistic processing rang-
ing from tokenization to deep grammatical depen-
dency analysis. It also performs named entity recog-
nition (NER) of the most usual named entity cat-
egories and recognizes temporal expressions. Lin-
guistic units manipulated by the parser are either
terminal categories or chunks. Each of these units
is associated with an attribute-value matrix that con-
tains the unit’s relevant morphological, syntactic and
semantic information.
Linguistic constituents are
linked by oriented and labelled n-ary relations de-
noting syntactic or semantic properties of the input
text. A Java API is provided with the parser so that
all linguistic structures and relations can be easily
manipulated by Java code.
In the following subsections, we give details of
the linguistic information that is used for the detec-
tion of salient dates.
4.2
Named Entity Recognition
Named Entity (NE) Recognition is one of the out-
puts provided by XIP. NEs are represented as unary
relations in the parser output. We used the exist-
ing NE recognition module of the English grammar
which tags the following NE types: location names,
person names and organization names. Ambigu-
ous NE types (ambiguity between type location or
organization for country names for instance) are
also considered.
4.3
Temporal Analysis
A previous module for temporal analysis was de-
veloped and integrated into the English grammar
(Hag`ege and Tannier, 2008), and evaluated during
TempEval campaign (Verhagen et al., 2007). This
module was adapted for tagging salient dates. Our
goal with temporal analysis is to be able to tag and
normalize3 a selected subset of temporal expressions
(TEs) which we consider to be relevant for our task.
This subset of expressions is described in the follow-
ing sections.
4.3.1
Absolute Dates
Absolute dates are dates that can be normalized
without external or contextual knowledge. This is
the case, for instance, of “On January 5th 2003”.
In these expressions, all information needed for nor-
malization is contained in the linguistic expression.
3We call normalization the operation of turning a temporal
expression into a formated, fully specified representation. This
includes finding the absolute value of relative dates.
However, absolute dates are relatively infrequent in
our corpus (7%), so in order to broaden the cover-
age for the detection of salient dates, we decided to
consider relative dates, which are far more frequent.
4.3.2
DCT-relative Dates
DCT-relative temporal expressions are those
which are relative to the creation date of the docu-
ment. This class represents 40% of dates extracted
from the AFP corpus. Unlike the absolute dates, the
linguistic expression does not provide all the infor-
mation needed for normalization. External informa-
tion is required, in particular, the date which corre-
sponds to the moment of utterance. In news articles,
this is the DCT. Two sub-classes of relative TEs can
be distinguished. The first sub-class only requires
knowledge of the DCT value to perform the normal-
ization. This is the case of expressions like next Fri-
day, which correspond to the calendar date of the
first Friday following the DCT. The second sub-class
requires further contextual knowledge for normal-
ization. For example, on Friday will correspond ei-
ther to last Friday or to next Friday depending on
the context where this expression appears (e.g. He
is expected to come on Friday corresponds to next
Friday while He arrived on Friday corresponds to
last Friday). In such cases, the tense of the verb
that governs the TE is essential for normalization.
This information is provided by the linguistic analy-
sis carried out by XIP.
4.3.3
Underspecified Dates
Considering the kind of corpus we deal with
(news), we decided to consider TEs whose granu-
larity is at least equal to a day. As a result, TEs
were normalized to a numerical YYYYMMDD for-
mat (where YYYY corresponds to the year, MM to
the month and DD to the day). In case of TEs with
a granularity superior to the day or month, DD and
MM fields remain unspecified accordingly. How-
ever, these underspecified dates are not used in our
experiments.
4.4
Modality and Reported Speech
An important issue that can affect the calculation of
salient dates is the modality associated with time-
stamped events in text. For instance, the status of a
salient date candidate in a sentence like “The meet-
ing takes place on Friday” has to be distinguished
from the one in “The meeting should take place on
Friday” or “The meeting will take place on Friday,
Mr. Hong said”. The time-stamped event meeting
takes place is factual in the first example and can
be taken as granted. In the second and third exam-
ples, however, the event does not necessarily occur.
This is expressed by the modality introduced by the
modal auxiliary should (second example), or by the
use of the future tense or reported speech (third ex-
ample). We annotate TEs with information regard-
ing the factuality of the event they modify. More
specifically, we consider the following features:
Events that are mentioned in the future:
If a
time-stamped event is in the future tense, we add a
specific attribute MODALITY with value FUTURE to
the corresponding TE annotation.
Events used with a modal verb:
If a time-
stamped event is introduced by a modal verb such
as should or would, then attribute MODALITY to the
corresponding TE annotation has the value MODAL.
Reported speech verbs:
Reported speech verbs
(or verbs of speaking) introduce indirect or reported
speech.
We dealt with time-stamped events gov-
erned by a reported speech verb, or otherwise ap-
pearing in reported speech. Once again, XIP’s lin-
guistic analysis provided the necessary information,
including the marking of reported speech verbs and
clause segmentation of complex sentences. If a rel-
evant TE modifies a reported speech verb, the anno-
tation of this TE contains a specific attribute, DE- CLARATION=”YES”.
If the relevant TE modifies
a verb that appears in a clause introduced by a re-
ported speech verb then the annotation contains the
attribute REPORTED=”YES”.
Note that the different annotations can be com-
bined (e.g. modality and reported speech can occur
for a same time-stamped event). For example, the
TE Friday in “The meeting should take place on Fri-
day, Mr. Hong said” is annotated with both modality
and reported speech attributes.
4.5
Corpus-dependent Special Cases
While we developed the linguistic and temporal an-
notators, we took into account some specificities of
our corpus.
We decided that the TEs today and
&lt;DCT value="20050105"/&gt;
&lt;EC TYPE="TIMEX" value="unknown"&gt;The year
2004&lt;/EC&gt; was the deadliest
&lt;EC TYPE="TIMEX" value="unknown"&gt;in a decade&lt;/EC&gt; for journalists
around the world, mainly because of the number of reporters killed in &lt;EC TYPE="LOCORG"&gt;Iraq&lt;/EC&gt;, the media rights group &lt;EN TYPE="ORG"&gt;Reporters Sans Frontieres&lt;/EN&gt; (Reporters Without Bor- ders) said &lt;EC TYPE="DATE" SUBTYPE="REL" REF="ST" DECLARATION="YES" value
="20050105"&gt;Wednesday&lt;/EC&gt;.
Figure 4: Example of XIP output for a sample article.
now were not relevant for the detection of salient
dates. In the AFP news corpus, these expressions
are mostly generic expressions synomymous with
nowadays and do not really time-stamp an event
with respect to the DCT. Another specificity of the
corpus is the fact that if the DCT corresponds to a
Monday, and if an event in a past tense is described
with the associated TE on Monday or Monday, it
means that this event occurs on the DCT day itself,
and not on the Monday before. We adapted the TE
normalizer to these special cases.
4.6
Implementation and Example
As said previously, a NER module is integrated into
the XIP parser, which we used “as is”. The TE tag-
ger and normalizer was adapted from (Hag`ege and
Tannier, 2008). We used the Java API provided with
the parser to perform the annotation and normal-
ization of TEs.
The output for the linguistic and
temporal annotation consists in XML files where
only selected information is kept (structural infor-
mation distinguishing headlines from news content,
DCT), and enriched with the linguistic annotations
described before (NEs and TEs with relevant at-
tributes corresponding to the normalization and typ-
ing). Information concerning modality, future tense
and reported speech, appears as attributes on the TE
tag. Figure 4 shows an example of an analyzed ex-
cerpt of a news article.
In this news excerpt, only one TE (Wednesday) is
normalized as both The year 2004 and in a decade
are not considered to be relevant. The first one being
a generic TE and the second one being of granular-
ity superior to a year. The annotation of the relevant
TE has the attribute indicating that it time-stamps an
event realized by a reported speech verb. The nor-
malized value of the TE corresponds to the 5th of
January 2005, which is a Wednesday. NEs are also
annotated.
In the entire AFP corpus, 11.5 millions temporal
expressions were detected, among which 845,000
absolute dates (7%) and 4.6 millions normalized
relative dates (40%).
Although we have not yet
evaluated our tagging of relative dates, the system
on which our current date normalization is based
achieved good results in the TempEval (Verhagen et
al., 2007) campaign.
5
Experiments and Results
In Section 5.1, we propose two baseline approaches
in order to give a good idea of the difficulty of the
task (Section 5.4 also discusses this point). In Sec-
tion 5.2, we present our experiments using simple
filtering and statistics on dates calculated by Lucene.
Finally, Section 5.3 gives details of our experiments
with a learning approach. In our experiments, we
used three different values to rank dates:
• occ(d) is the number of textual units (docu-
ments or sentences) containing the date d.
• Lucene provides ranked documents together
with their relevance score. luc(d) is the sum of
Lucene scores for textual units containing the
date d.
• An adaptation of classical tf.idf for dates:
tf.idf(d) = f(d).log
N
df(d)
where f(d) is the number of occurrences of
date d in the sentence (generally, f(d) = 1), N
is the number of indexed sentences and df(d)
is the number of sentences containing date d.
In all experiments (including baselines), timelines
have been built by considering only dates between
the first and the last dates of the corresponding man-
ual chronology. Processing runs were evaluated on
manually-written chronologies (see Section 3.2) ac-
cording to Mean Average Precision (MAP), which
is a widely accepted metric for ranked lists. MAP
gives a higher weight to higher ranked elements than
lower ranked elements.
Significance of evaluation
results are indicated by the p-value results of Stu-
dent’s t-test (t(90) = 1.9867).
Baselines “only DCTs”
Model
BLocc
DCT
BLluc
DCT
BLtf.idf
DCT
MAP Score
0.5036
0.5521
0.5523
Baselines “only absolute dates”
Model
BLocc
abs
BLluc
abs
BLtf.idf
abs
MAP Score
0.2627
0.2782
0.2778
Baselines “absolute dates or alternatively DCTs”
Model
BLocc
mix
BLluc
mix
BLtf.idf
mix
MAP Score
0.4005
0.4110
0.4135
Table 1: MAP results for baseline runs.
5.1
Baseline Runs
BLDCT . Indexing and search were done at docu-
ment level (i.e. each AFP article, with its title
and keywords, is a document). Given a query,
the top 10,000 documents were retrieved. In
these runs, only the DCT for each document
was considered. Dates were ranked by one of
the three values described above (occ, luc or
tf.idf) leading to runs BLocc
DCT , BLluc
DCT and
BLtfidf
DCT .
BLabs. Indexing and search were done at sentence
level (document title and keywords are added
to sentence text). Given a query, the top 10,000
sentences were retrieved. Only absolute dates
in these sentences were considered. We thus
obtained runs BLocc
abs, BLluc
abs and BLtfidf
abs .
Note that in this baseline, as well as in all the
subsequent runs, the information unit was the
sentence because a date was associated to a
small part of the text. The rest of the document
generally contained text that was not related to
the specific date.
BLmix. Same as BLabs, except that sentences con-
taining no absolute dates were considered and
associated to the DCT.
Table 1 shows results for these baseline runs.
Using only DCTs with Lucene scores or tf.idf(d)
already yielded interesting results,
with MAP
around 0.55.
5.2
Salient Date Extraction with XIP Results
and Simple Filtering
In these experiments, we considered a Lucene index
to be built as follows: each document was taken to
Model
MAP Score Model
MAP Score
Salient date runs with all dates
SDluc
0.6962
SDtf.idf
0.6982
Salient dates runs with filtering
SDluc
R
0.6975
SDtf.idf
R
0.6996
SDluc
F
0.6967
SDtf.idf
F
0.6993
∗∗
SDluc
M
0.6978
SDtf.idf
M
0.7005
∗
SDluc
D
0.7066
∗∗
SDtf.idf
D
0.7091
∗∗
SDluc
F MD
0.7086
∗∗
SDtf.idf
F MD
0.7112
∗∗
SDluc
RF MD
0.7127
∗∗
SDtf.idf
RF MD
0.7146
∗∗
Table 2: MAP results for salient date extraction with XIP
and simple filtering. Significance of filtering improve-
ment is indicated by Student t-test against no filtering (∗:
p &lt; 0.05 (significant); ∗∗: p &lt; 0.01 (highly significant)).
Improvement of using tf.idf(d) rather than occ(d) is also
highly significant.
be a sentence containing a normalized date. This
sentence was indexed with the title and keywords of
the AFP article containing it. Given a query, the top
10,000 documents were retrieved. Combinations be-
tween the following filtering operations were pos-
sible, by removing all dates associated with a re-
ported speech verb (R), a modal verb (M) and/or
a future verb (F). All these filtering operations were
intended to remove references to events that were
not certain, thereby minimizing noise in results.
These processing runs are named SD runs, with
indices representing the filtering operations. For ex-
ample, a run obtained by filtering modal and future
verbs is called SDM,F . In all combinations, dates
were ranked by the sum of Lucene scores for these
sentences (luc) or by tf.idf4.
Table 2 presents the results for this series of exper-
iments. MAP values are much higher than for base-
lines. Using tf.idf(d) is only very slightly better
than luc. Filtering operations bring some improve-
ment but the benefits of these different techniques
have to be further investigated.
5.3
Machine-Learning Runs
We used our set of manually-written chronologies
as a training corpus to perform machine learning
experiments. We used IcsiBoost5, an implementa-
4We do not present runs where dates are ranked by the num-
ber of times they appear in retrieved sentences (occ), as we did
for baselines, since results are systematically lower.
5http://code.google.com/p/icsiboost/
tion of adaptative boosting (AdaBoost (Freund and
Schapire, 1997)).
In our approach, we consider two classes: salient
dates are dates that have an entry in the manual
chronologies, while non-salient dates are all other
dates. This choice does, however, represent an im-
portant bias. The choices of journalists are indeed
very subjective, and chronologies must not exceed a
certain length, which means that relevant dates can
be thrown away. These issues will be discussed in
Section 5.4.
The classifier instances were not all sentences re-
trieved by the search engine. Using all sentences
would not yield a useful feature set. We rather ag-
gregated all sentences corresponding to the same
date before learning the classifier. Therefore, each
instance corresponded to a single date, and features
were figures concerning the set of sentences contain-
ing this date.
Features used in this series of runs are as follows:
1. Features representing the fact that the more
a date is mentioned, the more important it is
likely to be: 1) Sum of the Lucene scores for
all sentences containing the date 2) Number of
sentences containing the date 3) Ratio between
the total weights of the date and weights of all
returned dates 4) Ratio between the frequency
of the date and frequency of all returned dates;
2. Features representing the fact that an important
event is still written about, a long time after it
occurs: 1) Distance between the date and the
most recent mention of this date 2) Distance be-
tween the date and the DCT;
3. Other features: 1) Lucene’s best ranking of the
date 2) Number of times where the date is ab-
solute in the text 3) Number of times where
the date is relative (but normalized) in the text
4) Total number of keywords of the query in the
title, sentence and named entities of retrieved
documents 5) Number of times where the date
modifies a reported speech verb or is extracted
from reported speech.
We did not aim to classify dates, but rather to rank
them.
Instead, we used the predicted probability
P(d) returned by the classifier, and mixed it with
the Lucene score of sentences, or with date tf.idf:
Model
MAP Score
Machine-Learning Runs
MLluc
base
0.7033
MLluc
0.7905
∗∗
MLtf.idf
0.7918
∗∗
Table 3: MAP results for salient date extraction with
machine-learning. MLluc
base used Lucene scores and only
the first set of features described above.
MLluc and
MLtf.idf used the three sets of features.
They are both
highly significant under t-test (p ≈ 6.10−4).
score(d) = P(d) × val(d)
where val(d) is either luc(d) or tf.idf(d).
Because the task is very subjective and (above
all) because of the low quantity of learning data, we
prefered not to opt for a “learning to rank” approach.
We evaluated this approach with a classic 4-fold
cross-validation.
Our 91 chronologies were ran-
domly divided into 4 sub-samples, each of them be-
ing used once as test data. The final scores, pre-
sented in Table 3, are the average of these 4 pro-
cesses. As shown in this table, the learning approach
improves MAP results by about 0.05 point.
5.4</corps>
    <discussion>Discussion and Final Experiment
Chronologies hand-written by journalists are a very
useful resources for evaluation of our system, as they
are completely dissociated from our research and are
an exact representation of the output we aim to ob-
tain. However, assembling such a chronology is a
very subjective task, and no clear method for evalu-
ation agreement between two journalists seems im-
mediately apparent.
Only experts can build such
chronologies, and calculating this agreement would
require at least two experts from each domain, which
are hard to come by. One may then consider our sys-
tem as a useful tool for building a chronology more
objectively.
To illustrate this point, we chose four specific top-
ics6 and showed one of our runs on each topic to an
AFP expert for these subjects. We asked him to as-
sess the first 30 dates of these runs.
6Namely, “Arab revolt timeline for Morocco”, “Kyrgyzs-
tan unrest timeline”, “Lebanon’s new government: a timeline”,
“Libya timeline”.
Topic
APC
APE
Morocco
0.5847
0.5718
Kyrgyzstan
0.6125
0.9989
Libya
0.7856
1
Lebanon
0.4673
0.7652
Table 4: Average precision results for manual evaluation
on 4 topics, against the original chronologies (APC), and
the expert assessment (APE).
Table 4 presents results for this evaluation, com-
paring average precision values obtained 1) against
the original, manual chronologies (APC), and 2)
against the expert assessment (APE). These values
show that, for 3 runs out of 4, many dates returned
by the system are considered as valid by the expert,
even if not presented in the original chronology.
Even if this experiment is not strong enough to
lead to a formal conclusion (post-hoc evaluation
with only 4 topics and a single assessor), this tends
to show that our system produces usable outputs and
that our system can be of help to journalists by pro-
viding them with chronologies that are as useful and
objective as possible.
6</discussion>
    <conclusion>Conclusion and Future Work
This article presents a task of “date extraction” and
shows the importance of taking temporal informa-
tion into consideration and how with relatively sim-
ple temporal processing, we were able to indirectly
point to important events using the temporal infor-
mation associated with these events. Of course, as
our final goal consists in the detection of important
events, we need to take into account the textual con-
tent. In future work, we envisage providing, together
with the detection of salient dates, a semantic analy-
sis that will help determine the importance of events.
Another interesting direction in which we soon aim
to work is to consider all textual excerpts that are as-
sociated with salient dates, and use clustering tech-
niques to determine if textual excerpts correspond to
the same event or not. Finally, as our news corpus
is available both for English and French (compara-
ble corpus, not necessarily translations), we aim to
investigate cross-lingual extraction of salient dates
and salient events.</conclusion>
    <biblio>References
Salah A¨ıt-Mokhtar, Jean-Pierre Chanod, and Claude
Roux. 2002. Robustness beyond Shallowness: Incre-
mental Deep Parsing. Natural Language Engineering,
8:121–144.
James Allan, Rahul Gupta, and Vikas Khandelwal. 2001.
Temporal summaries of new topics. In Proceedings of
the 24th annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’01, pages 10–18.
James Allan, editor. 2002. Topic Detection and Tracking.
Springer.
Omar Alonso, Ricardo Baeza-Yates, and Michael Gertz.
2007.
Exploratory Search Using Timelines.
In
SIGCHI 2007 Workshop on Exploratory Search and
HCI Workshop.
Omar Rogelio Alonso. 2008. Temporal information re-
trieval. Ph.D. thesis, University of California at Davis,
Davis, CA, USA. Adviser-Gertz, Michael.
Regina Barzilay and Noemie Elhadad.
2002.
Infer-
ring Strategies for Sentence Ordering in Multidocu-
ment News Summarization. Journal of Artificial In-
telligence Research, 17:35–55.
Thorsten Brants, Francine Chen, and Ayman Farahat.
2003. A system for new event detection. In Proceed-
ings of the 26th annual international ACM SIGIR con-
ference on Research and development in informaion
retrieval, SIGIR ’03, pages 330–337, New York, NY,
USA. ACM.
Hai Leong Chieu and Yoong Keok Lee. 2004. Query
based event extraction along a timeline. In Proceed-
ings of the 27th annual international ACM SIGIR con-
ference on Research and development in information
retrieval, SIGIR ’04, pages 425–432.
Yoav Freund and Robert E. Schapire. 1997. A Decision-
Theoretic Generalization of On-Line Learning and an
Application to Boosting.
Journal of Computer and
System Sciences, 55(1):119–139.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S. Yu,
and Hongjun Lu. 2005. Parameter free bursty events
detection in text streams. In VLDB ’05: Proceedings
of the 31st international conference on Very large data
bases, pages 181–192.
Caroline Hag`ege and Xavier Tannier. 2008. XTM: A Ro-
bust Temporal Text Processor. In Computational Lin-
guistics and Intelligent Text Processing, proceedings
of 9th International Conference CICLing 2008, pages
231–240, Haifa, Israel, February. Springer Berlin /
Heidelberg.
Sanda Harabagiu and Cosmin Adrian Bejan.
2005.
Question Answering Based on Temporal Inference. In
Proceedings of the Workshop on Inference for Textual
Question Answering, Pittsburg, Pennsylvania, USA,
July.
Hyuckchul Jung, James Allen, Nate Blaylock, Will
de Beaumont, Lucian Galescu, and Mary Swift. 2011.
Building timelines from narrative clinical records: ini-
tial results based-on deep natural language under-
standing. In Proceedings of BioNLP 2011 Workshop,
BioNLP ’11, pages 146–154, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Nattiya Kanhabua.
2009.
Exploiting temporal infor-
mation in retrieval of archived documents.
In Pro-
ceedings of the 32nd Annual International ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval, SIGIR 2009, Boston, MA, USA, July 19-
23, 2009, page 848.
Youngho Kim and Jinwook Choi.
2011.
Recogniz-
ing temporal information in korean clinical narra-
tives through text normalization. Healthc Inform Res,
17(3):150–5.
Giridhar Kumaran and James Allen. 2004. Text clas-
sification and named entities for new event detection.
In SIGIR ’04: Proceedings of the 27th annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval, pages 297–304.
ACM.
Wei Li, Wenjie Li, Qin Lu, and Kam-Fai Wong. 2005a.
A Preliminary Work on Classifying Time Granulari-
ties of Temporal Questions. In Proceedings of Second
international joint conference in NLP (IJCNLP 2005),
Jeju Island, Korea, oct.
Zhiwei Li, Bin Wang, Mingjing Li, and Wei-Ying Ma.
2005b.
A Probabilistic Model for Restrospective
News Event Detection.
In Proceedings of the 28th
Annual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval, Sal-
vador, Brazil. ACM Press, New York City, NY, USA.
Thomas Mestl, Olga Cerrato, Jon Ølnes, Per Myrseth,
and Inger-Mette Gustavsen. 2009. Time Challenges -
Challenging Times for Future Information Search. D-
Lib Magazine, 15(5/6).
James Pustejovsky, Kiyong Lee, Harry Bunt, and Lau-
rent Romary.
2010.
Iso-timeml: An international
standard for semantic annotation. In Nicoletta Calzo-
lari (Conference Chair), Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,
Mike Rosner, and Daniel Tapias, editors, Proceed-
ings of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC’10), Valletta,
Malta, may. European Language Resources Associa-
tion (ELRA).
Claude Roux. 2004. Annoter les documents XML avec
un outil d’analyse syntaxique.
In 11`eme Confrence
annuelle de Traitement Automatique des Langues Na-
turelles, Fs, Maroc, April. ATALA.
Estela Saquete, Jose L. Vicedo, Patricio Mart´ınez-Barco,
Rafael Mu˜noz, and Hector Llorens. 2009. Enhancing
QA Systems with Complex Temporal Question Pro-
cessing Capabilities. Journal of Articifial Intelligence
Research, 35:775–811.
David A. Smith. 2002. Detecting events with date and
place information in unstructured text. In JCDL ’02:
Proceedings of the 2nd ACM/IEEE-CS joint confer-
ence on Digital libraries, pages 191–196, New York,
NY, USA. ACM.
Russell Swan and James Allen. 2000. Automatic genera-
tion of overview timelines. In Proceedings of the 23rd
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’00, pages 49–56, New York, NY, USA. ACM.
Marc Verhagen, Robert Gaizauskas, Franck Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 - 15: TempEval Temporal Rela-
tion Identification. In Proceedings of SemEval work-
shop at ACL 2007, Prague, Czech Republic, June. As-
sociation for Computational Linguistics, Morristown,
NJ, USA.
Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan, Xi-
aoming Li, and Yan Zhang.
2011a.
Timeline gen-
eration through evolutionary trans-temporal summa-
rization. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing,
EMNLP 2011, 27-31 July 2011, Edinburgh, UK, pages
433–443.
Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,
Xiaoming Li, and Yan Zhang.
2011b.
Evolution-
ary timeline summarization: a balanced optimization
framework via iterative substitution.
In Proceeding
of the 34th International ACM SIGIR Conference on
Research and Development in Information Retrieval,
SIGIR 2011, Beijing, China, July 25-29, 2011, pages
745–754.
Y. Yang, T. Pierce, and J. G. Carbonell. 1998. A study on
retrospective and on-line event detection. In Proceed-
ings of the 21st Annual International ACM SIGIR Con-
ference on Research and Development in Information
Retrieval, Melbourne, Australia, August. ACM Press,
New York City, NY, USA.</biblio>
</article>