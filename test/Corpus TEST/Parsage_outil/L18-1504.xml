<preamble>
L18-1504.pdf
</preamble>
<titre>
A New Annotated Portuguese/Spanish Corpus for the Multi-Sentence Compression Task
</titre>
<auteurs>
<auteur>Elvys Linhares Pontes</auteur>
<auteur>Juan-Manuel Torres-Moreno</auteur>
<auteur>Stéphane Huet (stephane.huet}@univ-avignon.fr)</auteur>
<affiliation>
CERI/LIA, Université d’Avignon et des Pays de Vaucluse, Avignon, France
2
École Polytechnique de Montréal, Montréal, Canada
3
Universidade Federal do Ceará, Sobral-CE, Brasil
{elvys.linhares-pontes, juan-manuel.torres, stephane.huet}@univ-avignon.fr
</affiliation>
</auteurs>
<abstract>
                                                             Abstract
Multi-sentence compression aims to generate a short and informative compression from several source sentences that deal with the same
topic. In this work, we present a new corpus for the Multi-Sentence Compression (MSC) task in Portuguese and Spanish. We also
provide on this corpus a comparison of two state-of-the-art MSC systems.

Keywords: Annotated Corpus, Multi-Sentence Compression, Multilingual Corpus.


</abstract>
<introduction>
                    1.       Introduction
Among the various applications of Natural Language Pro-
cessing, Automatic Text Summarization (ATS) aims at
summarizing one or more texts automatically. Summariza-
tion systems identify relevant data and create a summary
from key information. The (Multi-)Sentence Compression
task can be seen as a subproblem of ATS with the objective
to generate a shorter, informative and correct sentence from
source sentence(s).
In many cases, state-of-the-art NLP systems are evaluated
with experiments restrained to the English language, in part
because there are a lot of available English resources for
most NLP tasks. As regards Multi-Sentence Compression
(MSC), the available resources are unfortunately limited; to
our knowledge, only one dataset is freely available and it is
confined to the French language (Boudin and Morin, 2013).
In this work, we present a new annotated corpus in the Por-
tuguese and Spanish languages for the MSC task. Using
this corpus, we evaluate two state-of-the-art systems and
show that the use of several languages leads to more miti-
gated results on the superiority of one system than the use
of the French corpus alone.

The remainder of this paper is organized as follows. In Sec-

tion 2, we characterize MSC with respect to related tasks

from the perspective of the available corpora. Section 3

describes the creation and the features of our corpus. In

Section 4 we analyze the results achieved by state-of-the-

art methods using our dataset. Finally, conclusions are set

out in Section 5.

</introduction>
<Results>
   Table 3 shows f-score ROUGE scores for the French, Por-
   tuguese and Spanish datasets.8 Boudin and Morin’s system
   generated better compressions with higher ROUGE scores
   than Filippova’s and the baseline for all datasets.

      6
         Website:          http://www.florianboudin.org/
   publications.html
       7
         http://snowball.tartarus.org/
       8
         Although we used the same system and data as (Boudin and
   Morin, 2013) for the French corpus, we were not able to repro-
   duce exactly their results. The ROUGE scores given in their arti-
   cle are close to ours for their system: 0.6568 (ROUGE-1), 0.4414
   (ROUGE-2) and 0.4344 (ROUGE-SU4), but using Filippova’s
   system we measured higher scores than them: 0.5744 (ROUGE-
   1), 0.3921 (ROUGE-2) and 0.3700 (ROUGE-SU4).
                                           French                        Portuguese                          Spanish
  Method
                                RG-1      RG-2 RG-SU4             RG-1     RG-2   RG-SU4           RG-1      RG-2      RG-SU4
  Baseline                      0.3681    0.1904  0.1758          0.3199 0.1273     0.1309        0.2700    0.0990      0.0984
  Filippova (2010)              0.6384    0.4423  0.4297          0.5388 0.2971     0.2938        0.5004    0.2983      0.2847
  Boudin and Morin (2013)       0.6674    0.4672  0.4602          0.5532 0.3029     0.2868        0.5140    0.2960      0.2801

Table 3: ROUGE f-scores measured on the French, Portuguese and Spanish datasets. The best ROUGE results are in bold.



Table 4 provides statistics on the length and the compres-
sion ratio of the sentences generated by the systems. The
baseline system output the shortest compressions, which
translated into the worst ROUGE scores. For the three
tested datasets, Filippova’s method generated shorter com-
pressions with a smaller standard deviation than Boudin
and Morin’s system. Let us note that for this last system
the lengths of the outputs are less regular across the three
languages.
The Portuguese and Spanish languages derive from Latin
and are closely related languages. However, they differ in
many details of their grammar and lexicon. Moreover, the
datasets produced for the three languages are unlike accord-
ing to several features. First, our corpus contains a smaller
(Portuguese corpus) and a larger (Spanish corpus) dataset
in terms of sentences than the original French corpus. Be-
sides, the compression rates of the three datasets (see Sec-
tion 3.) indicates that the Portuguese source sentences have
more irrelevant tokens. The sentence similarity (Table 1,
last line) describes the variability of sentences in the source
sentences and in the references, and reflects here that the
sentences are slightly more diverse for the Portuguese cor-
pus. It can be noticed that the references are more similar
too each other than source sentences since they only retain
the main information. Finally, the French corpus has a TTR
of 38.8% whereas the Portuguese and Spanish datasets have
TTRs of 33.7% and 35.2%, respectively.
The baseline system generated the shortest compression be-
cause all arcs of the WG have the same weights. However,
this system analyzes neither the grammaticality nor the
most used n-grams in the clusters. Consequently, the base-
line system generated compressions with the worst ROUGE
scores.
</Results>
<conclusion>
          5.    Conclusion and Future Work

  Multi-Sentence Compression aims to generate a short infor-
  mative text summary from several sentences with related
  and redundant information. This task can be used in the
  domain of multi-document summarization or question an-
  swering to provide more informative and concise texts.
  In this paper, we presented a new annotated corpus in
  two languages that extends the French data made available
  in (Boudin and Morin, 2013). We also compared two state-
  of-the art systems on this new dataset. We hope this cor-
  pus will help the NLP community to develop and validate
  multi-language methods for multi-sentence compression.
  In order to extend the multi-language resources to more di-
  verse languages, we plan to create a similar MSC dataset
  for Arabic. We also want to use our corpus to test other
  competitive MSC systems, such as the one based on integer
  linear programming we introduced in (Linhares Pontes et
  al., 2016).
</conclusion>
<Reference : >
   References are assumed to contain the most important

   information. Thus we calculated informativeness scores

   based on the common information between the output of

   the MSC system and the references using ROUGE (Lin,

   2004). In particular, we used the f-measure metrics

   ROUGE-1, ROUGE-2 and ROUGE-SU4. Like in Boudin

   and Morin (Boudin and Morin, 2013), ROUGE metrics are

   calculated using stop words removal and stemming.7

   We also led a manual evaluation with 4 native speakers

   for each language. The native speakers of each language

   judged the compression in two aspects: informativeness

   and grammaticality. In the same way as (Filippova, 2010;

   Boudin and Morin, 2013), the native speakers evaluated the
   grammaticality in a 3-point scale: 0 point for an ungram-
   matical compression, 1 point for compression with minor
   mistakes; and 2 points for a correct compression. The in-
   formativeness evaluation process is similar for grammati-
   cality: 0 point if the compression is not related to the main
   topic, 1 point if the compression misses some relevant in-
   formation and 2 points if the compression conveys the gist
   of the main event.
   4.2.   Results with Automatic Metrics
   Table 3 shows f-score ROUGE scores for the French, Por-
   tuguese and Spanish datasets.8 Boudin and Morin’s system
   generated better compressions with higher ROUGE scores
   than Filippova’s and the baseline for all datasets.

      6
         Website:          http://www.florianboudin.org/
   publications.html
       7
         http://snowball.tartarus.org/
       8
         Although we used the same system and data as (Boudin and
   Morin, 2013) for the French corpus, we were not able to repro-
   duce exactly their results. The ROUGE scores given in their arti-
   cle are close to ours for their system: 0.6568 (ROUGE-1), 0.4414
   (ROUGE-2) and 0.4344 (ROUGE-SU4), but using Filippova’s
   system we measured higher scores than them: 0.5744 (ROUGE-
   1), 0.3921 (ROUGE-2) and 0.3700 (ROUGE-SU4).
                                           French                        Portuguese                          Spanish
  Method
                                RG-1      RG-2 RG-SU4             RG-1     RG-2   RG-SU4           RG-1      RG-2      RG-SU4
  Baseline                      0.3681    0.1904  0.1758          0.3199 0.1273     0.1309        0.2700    0.0990      0.0984
  Filippova (2010)              0.6384    0.4423  0.4297          0.5388 0.2971     0.2938        0.5004    0.2983      0.2847
  Boudin and Morin (2013)       0.6674    0.4672  0.4602          0.5532 0.3029     0.2868        0.5140    0.2960      0.2801

Table 3: ROUGE f-scores measured on the French, Portuguese and Spanish datasets. The best ROUGE results are in bold.



Table 4 provides statistics on the length and the compres-
sion ratio of the sentences generated by the systems. The
baseline system output the shortest compressions, which
translated into the worst ROUGE scores. For the three
tested datasets, Filippova’s method generated shorter com-
pressions with a smaller standard deviation than Boudin
and Morin’s system. Let us note that for this last system
the lengths of the outputs are less regular across the three
languages.
The Portuguese and Spanish languages derive from Latin
and are closely related languages. However, they differ in
many details of their grammar and lexicon. Moreover, the
datasets produced for the three languages are unlike accord-
ing to several features. First, our corpus contains a smaller
(Portuguese corpus) and a larger (Spanish corpus) dataset
in terms of sentences than the original French corpus. Be-
sides, the compression rates of the three datasets (see Sec-
tion 3.) indicates that the Portuguese source sentences have
more irrelevant tokens. The sentence similarity (Table 1,
last line) describes the variability of sentences in the source
sentences and in the references, and reflects here that the
sentences are slightly more diverse for the Portuguese cor-
pus. It can be noticed that the references are more similar
too each other than source sentences since they only retain
the main information. Finally, the French corpus has a TTR
of 38.8% whereas the Portuguese and Spanish datasets have
TTRs of 33.7% and 35.2%, respectively.
The baseline system generated the shortest compression be-
cause all arcs of the WG have the same weights. However,
this system analyzes neither the grammaticality nor the
most used n-grams in the clusters. Consequently, the base-
line system generated compressions with the worst ROUGE
scores.

4.3.   Human Evaluation
ROUGE only analyzes the overlapping between the candi-
date compression and the references. Since this analysis is
not reliable enough, we led a further manual evaluation to
study the informativeness and grammaticality of compres-
sions, as described in Section 4.1.. Given the poor results
of the baseline with ROUGE, we only analyzed the Filip-
pova’s and Boudin and Morin’s methods (Table 5).
We measured inter-rater agreement on the judgments we
collected, obtaining values of Fleiss’ kappa of 0.418, of
0.305 and 0.364 for French, Portuguese and Spanish re-
spectively. These results show that human evaluation is
rather subjective. Questioning evaluators on how they pro-
ceed to rate sentences reveals that they often made their

choice by comparing outputs for a given cluster. As the
differences of the grammaticality and the informativeness
scores for the methods are not statistically significant, we

                                                              319



  move our investigation on the average and standard de-
  viation of the results. Both methods generated compres-
  sions of good quality (scores higher than 1) for all datasets,
  especially for the French and the Portuguese parts where
  scores above 1.5 for grammaticality and above 1.2 for in-
  formativeness were obtained. Filippova’s method gener-
  ated more correct compressions (except for the Portuguese
  corpus where both methods obtained almost the same re-
  sults), which shows that the re-ranking step tends to mod-
  erately deteriorate grammaticality. By contrast, Boudin
  and Morin’s method consistently improves informative-
  ness, which validates the interest of integrating the anal-
  ysis of key phrases inside candidate compressions. This re-
  ranking method combines the cohesion score of Filippova
  and the relevance of key phrases9 to generate more infor-
  mative compression. This method selects the path of Word
  Graph that has relevant key phrases even if this path has a
  lower cohesion quality.
  All in all, Boudin and Morin’s method generated more in-
  formative but also longer compressions than Filippova’s,
  CR showing a relative increase of 18% between both sys-
  tems (Table 4).

          5.    Conclusion and Future Work

  Multi-Sentence Compression aims to generate a short infor-
  mative text summary from several sentences with related
  and redundant information. This task can be used in the
  domain of multi-document summarization or question an-
  swering to provide more informative and concise texts.
  In this paper, we presented a new annotated corpus in
  two languages that extends the French data made available
  in (Boudin and Morin, 2013). We also compared two state-
  of-the art systems on this new dataset. We hope this cor-
  pus will help the NLP community to develop and validate
  multi-language methods for multi-sentence compression.
  In order to extend the multi-language resources to more di-
  verse languages, we plan to create a similar MSC dataset
  for Arabic. We also want to use our corpus to test other
  competitive MSC systems, such as the one based on integer
  linear programming we introduced in (Linhares Pontes et
  al., 2016).

                  6.   Acknowledgments
  This work was partially financed by the European Project
  CHISTERA-AMIS ANR-15-CHR2-0001.

      9
        Key phrases are multi-word phrases composed of the syn-
  tactic pattern (ADJ)∗ (N P P |N C)+ (ADJ)∗ , which ADJ are
  adjectives, NPP are proper nouns and NC are common nouns.
  French, Portuguese and Spanish have similar syntactic patterns.

</Reference : >
