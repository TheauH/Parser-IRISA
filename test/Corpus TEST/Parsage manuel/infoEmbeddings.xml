<article>
    <preamble>infoEmbeddings.pdf</preamble>
    <titre>An Empirical Evaluation of Text Representation Schemes on Multilingual Social Web to Filter the Textual Aggression</titre>
    <auteurs>
        <auteur>Sandip Modha (sjmodha@gmail.com)</auteur>
        <auteur>Prasenjit Majumder (prasenjit.majumder@gmail.com)</auteur>
        <affiliation>DA-IICT Gandhinagar, India</affiliation>
    </auteurs>
    <abstract>ABSTRACT
Due to an exponential rise in the social media user base, incidents like hate speech,
trolling, cyberbullying are also increasing and that lead hate speech detection prob-
lem reshaped into different tasks like Aggression detection, Fact detection. This
paper attempt to study the effectiveness of text representation schemes on two
tasks namely: User Aggression and Fact Detection from the social media contents.
In User Aggression detection, The aim is to identify the level of aggression from
the contents generated in the Social media and written in the English, Devanagari
Hindi and Romanized Hindi. Aggression levels are categorized into three predefined
classes namely: ‘Non-aggressive‘, ‘Overtly Aggressive‘, and ‘Covertly Aggressive‘.
During the disaster-related incident, Social media like, Twitter is flooded with mil-
lions of posts. In such emergency situations, identification of factual posts is impor-
tant for organizations involved in the relief operation. We anticipated this problem
as a combination of classification and Ranking problem. This paper presents a com-
parison of various text representation scheme based on BoW techniques, distributed
word/sentence representation, transfer learning on classifiers. Weighted F1 score is
used as a primary evaluation metric. Results show that text representation using
BoW performs better than word embedding on machine learning classifiers. While
pre-trained Word embedding techniques perform better on classifiers based on deep
neural net. Recent transfer learning model like ELMO, ULMFiT are fine-tuned
for the Aggression classification task. However, results are not at par with pre-
trained word embedding model. Overall, word embedding using fastText produce
best weighted F1-score than Word2Vec and Glove. Results are further improved
using pre-trained vector model. Statistical significance tests are employed to en-
sure the significance of the classification results. In the case of lexically different
test Dataset, other than training Dataset, deep neural models are more robust and
perform substantially better than machine learning classifiers.</abstract>
    <introduction>Table 1.
sample post for the each class.
Post text
Class Label
1
She is simple girl and need not know politics. Let her vote to
her choice
NAG
2
People talk about common man suffering all the time.This is
the same country where thousands laid their lives for free-
dom.Cant the common man endure little trouble to stand in
queues for the greater good
CAG
3
Langove get out from this conversation. U are an uninvited
dog here
OAG
1. Introduction
The Social Web is a great source for studying human interaction and behavior. In
the last few years, there is an exponential growth in Social Media user base. Sensing
content of Social Media like Facebook, Twitter, by the smart autonomous application
empower its user community with real-time information which is unfolded across the
different part of the world. Social media provide the easiest and anonymous platform
for common people to voice their opinion or view on a various entity like celebrity,
politician, product, stock market etc or any social movement. Sometime such opinions
might be aggressive in nature and propagate hate in the social media community.
With the unprecedented increase in the user base of the social media and its avail-
ability on the Smartphones, incidents like Hate speech, trolling, Cyberbullying, and
Aggressive posts are increasing exponentially. A smart autonomous system is required
which enable surveillance on the social media platform and detect such incidents.
Some of the researchers look posts from the aspect like aggression Kumar Ritesh et
al. (2018) to filter the contents. some of the posts contain words which might be qual-
ified as either highly or overly aggressive or have hidden aggression. Sometimes posts
do not have any aggression. Based on these, posts or comments are categorized into
three classes namely: ‘Overtly Aggressive‘, ‘Covertly Aggressive‘ and ‘Non-aggressive‘
Kumar Ritesh et al. (2018). Henceforth, in the rest of the paper, we will denote these
classes by these abbreviations namely: OAG, CAG, NAG respectively.Table 1 shows
the sample posts belonging to these classes.
Social Media, specifically Microblog has proved its importance during the disaster-
related incidents like an earthquake, Hurricane and floods 1. Organizations involved
in relief operation actively track posts related to situational information posted on
Facebook and Twitter during the disaster. However, At the same time, social media
is flooded with lots of prayer and condolence messages. Posts which contain factual
information are extremely important for the organization involved in post-disaster
relief operations for coordination. Filtering and Ranking of the posts containing factual
information will be very useful to them. We believe that this is the special problem
of the Sentiment Analysis task. We consider this problem as a combination of two-
class classification problem: factual posts and nob-factual posts plus Ranking. Table
2 shows the example of the posts of belong to these class.
The Text representation of social web content plays a pivotal role in any NLP task.
Bag-of-word is the oldest and simple technique to represent the document or post into
a fixed length vector. The BoW techniques generate very sparse and high dimensional
space vector. Text representation using distributed word/sentence representation or
word embedding is gain rapid momentum recently. In this paper, one of the objectives
1https://phys.org/news/2018-08-social-media-bad-disaster-zones.html
Table 2.
sample post for the each class.
Post text
Class Label
1
#Nepal #Earthquake day four. Slowly in the capital valley
Internet and electricity beeing restored . A relief for at least
some ones
Factual
2
PMOIndia Indian Government is doing every possible help to
the earthquake victims and they need money so plz contribute
Non-factual
is to find the best text representation scheme to model social web content for the
machine learning classifier and deep neural net. Various Text representation scheme
based on BoW, word embedding and are studied empirically. We have reported result
on popular word embedding technique like Word2vec, Glove and fastText on stan-
dard machine learning classifier like Multinomial Naive Bayes (MNB), Logistic Re-
gression(LR), K-Nearest neighbors KNN, Support Vector Classifier (SVC), Decision
Tree (DT),Stochastic Gradient Descent(SGD), Random forest (RF), Ridge, AdaBoost,
Perceptron, Deep neural net based on LSTM, CNN and Bidirectional LSTM. Results
are also reported on Doc2vec embedding, a popular sentence or paragraph embedding
technique for the above classifiers.
Transfer Learning is well practiced in the area of computer vision. However, in the
NLP, transfer learning has limited application in the form of pre-trained word vector
which is used to initialize the weights of the embedding layer of the deep neural net-
work. With the advent of transfer learning method like ELMO (Peters et al. , 2018),
ULMFiT (Howaard et al., 2018) claimed substantial improvement in the performance
of various NLP tasks like Sentiment Analysis, Question/Answering, Textual Entail-
ment empirically. The main idea behind these methods is to train language model
on the large corpus and fine tune on the task-specific corpus. In this paper, We have
evaluated the performance of these methods in the Aggression classification tasks.
1.1. Research Questions
In this study, experiments are performed on the benchmark dataset with to answer
the following questions
• Which is the best Text Representation scheme to model text from the Social
Web?
• Does pre-trained language model based on transfer learning better than pre-
trained word embedding based on shallow transfer learning on Social media
data?
• Does Making too Deep Neural net make sense?
To answer all research question listed above, experiments are performed on two
tasks namely: Aggression detection (Trolling Aggression and Cyberbullying (TRAC)
dataset) Kumar et al. (2018) and Fact detection (FIRE iRMDI Dataset)Basu et al.
(2018). In this paper, we present exhaustive benchmarking of text representation
schemes on these datasets. Our results reveal that fastText with pre-trained vector
along with CNN outperform standard machine learning classifiers based on BoW
Model and marginally perform better than Word2vec and Glove. Paragraph vector
or Doc2vec Le, Quoc et al. (2014) perform very poor on our dataset and turn out to
be the worst text representation scheme among all. We also found that model based
on the deep neural net is more robust than machine learning classifier when tested
on lexically different dataset than training Dataset. i.e. deep neural model substan-
tially outperforms machine learning classifier on Twitter test Dataset while trained on
Facebook Dataset in this evaluation.
To validate our claims, statistical significance tests are performed on weighted F1-
score of the classifier for each text representing scheme. Statistical inference is used
to check evidence to support or reject these claims. Significance tests like Wilcoxon
signed-rank and Student t-test were carried out by comparing weighted F1 score all
the text representation scheme with the fastText pre-trained vector. In most of the
cases, p-values are less than 0.05.
The rest of the paper is organized as follows: In section 2, we review the relevant
works in the area of Sentiment analysis and hate speech detection. Section 3 contains
the detail information about the various benchmark Datasets used in the experiments.
Various Text Representation schemes are described in section 4. We formally describe
the evaluation task and models in section 5. We report results in section 6 and present
detail result analysis in section 7. We conclude the discussion and provide insight for
the future work in section 8.</introduction>
    <results>6. Results
In this section, we first present results of classifiers TRAC dataset Kumar et al. (2018) with different text representation scheme. Latter we present result on FIRE IRMiDis 2018 Dataset. Tweets are very noisy in nature contains user mentions, Hash- tags, Emojis, and URLs. We do not perform any kind of text pre-processing on tweets in experiments with deep neural models. In experiments with machine learning classi- fier, before classification, Hashtag symbol # and User mentions are dropped from the tweets. Non-ASCII characters and stop-words are removed from tweet text (Modha et al. , 2016).</results>

    <conclusion>8. Conclusion
In this Paper, Multilingual Social media stream is studied with special kind of text
features: Aggression and fact perspective. Exhaustive experiments are performed to
benchmark the text representation scheme on machine learning classifiers and deep
neural nets. From the results, we conclude that deep Neural model with pre-trained
word embedding is the better choice than machine earning classifier and transfer learn-
ing model. Word embedding is the better text representative scheme than Bag-of-words
for the deep neural models. In fact, performance can be improved with the help of fast-
Text pre-trained vector. However, machine learning classifiers perform better in BoW
with TF/IDF weighting than word embedding. We also concluded that higher drop
out will help to counter model overfitting and improvise a standard evaluation metrics.
CNN and LSTM are the better models for these datasets. On the English test corpus,
we obtained a better weighted F1 score for NAG class and poor weighted F1 score
for CAG class which supports the previous (Malmasi, et al. , 2017) findings. For the
Facebook Hindi test corpus, the same seems not to be true. We obtained a better F1
score for CAG class than NAG class. It is also to be noted that the model leads to
poor result on Twitter test data since the training corpus was created from Facebook.
In such cases, deep neural models substantially outperform machine learning classi-
fiers. Significance test confirms these claims with 95 % confidence interval in most the
cases. Our work shows what kind of problems are moving into the center of attention
for research in machine learning. Using deep learning models, there is great potential
to solve some of these problems, yet still, the performance is far from perfect. Model
transfer between problems and the application of derived knowledge in user interfaces
are areas directions for future work.</conclusion>
    <biblio>References
Aroyehun, Segun Taofeek and Gelbukh, Alexander (2018). Aggression detection in social media:
Using deep neural networks, data augmentation, and pseudolabeling.Proceedings of the First
Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pp.90–97.
Arroyo-Fern´andez, Ignacio and Forest, Dominic and Torres-Moreno, Juan-Manuel and
Carrasco-Ruiz, Mauricio and Legeleux, Thomas and Joannette,Karen (2018). Cyberbullying
Detection Task: the EBSI-LIA-UNAM System (ELU) at COLING’18 TRAC-1.Proceedings
of the First Workshop on Trolling,Aggression and Cyberbullying (TRAC-2018), pp 140–149.
Basu, Moumitaand Ghosh, Saptarshi and Ghosh, Kripabandhu (2018). Overview of the FIRE
2018 track: Information Retrieval from Microblogs during Disasters (IRMiDis). Proceedings
of FIRE 2018 - Forum for Information Retrieval Evaluation, Gujrat, India, December .
Baziotis, Christos and Pelekis, Nikos and Doulkeridis, Christos (2017). Datastories at semeval-
2017 task 4: Deep lstm with attention for message-level and topic-based sentiment analysis.
Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017),
pp.747–754
Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas (2017) En-
riching word vectors with subword information, Transactions of the Association for Compu-
tational Linguistics, vol-5,pp.135–146, MIT Press.
Burnap, Pete and Williams, Matthew Ltitle (2015). Cyber hate speech on twitter: An applica-
tion of machine classification and statistical modeling for policy and decision makingPolicy
&amp; Internet, vol-7 number 2, pp.223–242, Wiley Online Library.
Conover, Michael and Ratkiewicz, Jacob and Francisco, Matthew R and Gon¸calves , Bruno and
Menczer, Filippo and Flammini, Alessandro (2011). Political polarization on twitter.,Icwsm,
vol-133, pp.89–96.
Conover, Michael D and Gon¸calves, Bruno and Ratkiewicz, Jacob and Flammini, Alessandro
and Menczer, Filippo (2011). Predicting the political alignment of twitter users, Privacy,
Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social
Computing (SocialCom), 2011 IEEE Third International Conference on, pp.192–199.
Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar (2017). Au-
tomated Hate Speech Detection and the Problem of Offensive Langemuage. Proceedings of
ICWSM.
Deriu, Jan and Gonzenbach, Maurice and Uzdilli, Fatih and Lucchi, Aurelien and Luca, Valeria
De and Jaggi, Martin (2016). Swisscheese at semeval-2016 task 4: Sentiment classification
using an ensemble of convolutional neural networks with distant supervision. Proceedings of
the 10th international workshop on semantic evaluation,pp.1124–1128.
Hltcoe, J (2013).Semeval-2013 task 2: Sentiment analysis in Twitter,vol-312 Atlanta, Georgia,
USA.
Howard, Jeremy &amp; Ruder, Sebastian 2018. Universal language model fine-tuning for text clas-
sification”,arXiv preprint arXiv:1801.06146,
Harris, Zellig S (1954),Distributional structure Word,10, number=2-3,pp.146–162, 1954, Taylor
&amp; Francis.
Kumar, Ritesh and Reganti, Aishwarya N. and Bhatia, Akshit and Maheshwari,Tushar (2018),
Aggression-annotated Corpus of Hindi-English Code-mixed Data, Proceedings of the 11th
Language Resources and Evaluation Conference (LREC), Miyazaki, Japan.
Kumar, Ritesh and Ojha, Atul Kr. and Malmasi, Shervin and Zampieri Marcos (2018). Bench-
marking Aggression Identification in Social Media, Proceedings of the First Workshop on
Trolling, Aggression and Cyberbulling (TRAC), Santa Fe, USA
Kwok, Irene and Wang, Yuzhou (2013),Locate the hate: Detecting Tweets Against Blacks
,Twenty-Seventh AAAI Conference on Artificial Intelligence.
Lau, Jey Han and Baldwin, Timothy (2016). An empirical evaluation of doc2vec with practical
insights into document embedding generation. arXiv preprint arXiv:1607.05368.
Le, Quoc and Mikolov, Tomas (2014) Distributed representations of sentences and docu-
ments.International Conference on Machine Learning, pp.1188–1196
Majumder, Prasenjit and Mandl, Thomas and Modha Sandip (2018)Filtering Aggression from
the Multilingual Social Media Feed Proceedings of the First Workshop on Trolling, Aggres-
sion and Cyberbullying (TRAC-2018), pp. 199–207
Malmasi, Shervin and Zampieri, Marcos (2017)Detecting Hate Speech in Social Media Pro-
ceedings of the International Conference Recent Advances in Natural Language Processing
(RANLP), pp.467–472.
Malmasi, Shervin and Zampieri, Marcos (2018).Challenges in Discriminating Profanity from
Hate Speech Journal of Experimental &amp; Theoretical Artificial Intelligence pp.1–16, vol-30,
issue-2,Taylor &amp; Francis.
Maynard, Diana and Funk, Adam (2011) Automatic detection of political opinionsin tweets,
Extended Semantic Web Conference,pp. 88–99, Springer.
Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey (2013). Efficient estima-
tion of word representations in vector space,arXiv preprint arXiv:1301.3781.
Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin,
Armand (2018). Advances in Pre-Training Distributed Word Representations,Proceedings of
the International Conference on Language Resources and Evaluation (LREC 2018).
Modha, Sandip and Agrawal, Krati and Verma, Deepali and Majumder, Prasenjit and Man-
dalia, Chintak 2016. DAIICT at TREC RTS 2016: Live Push Notification and Email Di-
gest.,TREC.
Mohammad, Saif M and Kiritchenko, Svetlana and Zhu, Xiaodan (2013). NRC-Canada: Build-
ing the state-of-the-art in sentiment analysis of tweets.arXiv preprint arXiv:1308.6242.
Nakov, Preslav and Ritter, Alan and Rosenthal, Sara and Sebastiani, Fabrizio and Stoyanov,
Veselin (2016). SemEval-2016 task 4: Sentiment analysis in Twitter,Proceedings of the 10th
international workshop on semantic evaluation (semeval-2016), pp. 1–18.
Pennington, Jeffrey and Socher, Richard and Manning, Christopher Glove: Global vectors for
word representation Proceedings of the 2014 conference on empirical methods in natural
language processing (EMNLP), pp.1532–1543.
Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark,
Christopher and Lee, Kenton and Zettlemoyer, Luke (2018). Deep contextualized word rep-
resentations arXiv preprint arXiv:1802.05365.
Razavi, Amir H and Inkpen, Diana and Uritsky, Sasha and Matwin, Stan (2010) Offensive
language detection using multi-level classification, Canadian Conference on Artificial Intel-
ligence pp.16–27, Springer
Rosenthal, Sara and Nakov, Preslav and Kiritchenko, Svetlana and Mohammad, Saif and Rit-
ter, Alan and Stoyanov, Veselin (2015). Semeval-2015 task 10: Sentiment analysis in twit-
ter Proceedings of the 9th international workshop on semantic evaluation (SemEval 2015),
pp.451–463.
Rosenthal, Sara and Farra, Noura and Nakov, Preslav (2017). SemEval-2017 task 4: Sentiment
analysis in Twitter Proceedings of the 11th International Workshop on Semantic Evaluation
(SemEval-2017), pp.502–518.
Schmidt, Anna and Wiegand, Michael (2017).A Survey on Hate Speech Detection Using Natural
Language Processing,Proceedings of the Fifth International Workshop on Natural Language
Processing for Social Media. Association for Computational Linguistics Valencia, Spain,
pp.1–10,
Severyn, Aliaksei and Moschitti, Alessandro (2015) Unitn: Training deep convolutional neural
network for twitter sentiment classification, Proceedings of the 9th international workshop
on semantic evaluation (SemEval 2015), pp. 464–469.
Tumasjan, Andranik and Sprenger, Timm Oliver and Sandner, Philipp G and Welpe, Isabell
M (2010). Predicting elections with twitter: What 140 characters reveal about political sen-
timent.,Icwsm, vol-10, number-1, pp. 178–185.
Warner, William and Hirschberg, Julia (2012) Detecting hate speech on the world wide web,
Proceedings of the Second Workshop on Language in Social Media,pp 19–26,Association for
Computational Linguistics.
Xu, Jun-Ming and Jun, Kwang-Sung and Zhu, Xiaojin and Bellmore, Amy (2012). Learning
from bullying traces in social media, Proceedings of the 2012 conference of the North Amer-
ican chapter of the association for computational linguistics: Human language technologies,
pp.656–666, Association for Computational Linguistics
Zhang, Ye and Wallace, Byron (2015). A Sensitivity Analysis of (and Practitioners’ Guide to)
Convolutional Neural Networks for Sentence Classification,arXiv preprint arXiv:1510.03820.
Majumder, Prasenjit and Mitra, Mandar and Pal, Dipasree and Bandyopadhyay, Ayan and
Maiti, Samaresh and Mitra, Sukanya and Sen, Aparajita and Pal, Sukomal.Text collections
for FIRE, Proceedings of the 31st annual international ACM SIGIR conference on research
and development in information retrieval,pp.699–700,ACM
Majumdar, P and Mitra, Mandar and Parui, Swapan K and Bhattacharya, Initiative for indian
language ir evaluation, The First International Workshop on Evaluating Information Access
(EVIA)</biblio>
</article>