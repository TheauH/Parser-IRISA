                On the Development of the RST Spanish Treebank
       Iria da Cunha                 Juan-Manuel Torres-Moreno                              Gerardo Sierra
    Institute for Applied                Laboratoire Informatique                  Instituto de Ingeniería (UNAM),
  Linguistics (UPF), Spain             d’Avignon (UAPV), France                                  Mexico
   Instituto de Ingeniería           Instituto de Ingeniería (UNAM),                gsierram@iingen.unam.
     (UNAM), Mexico                                Mexico                                          mx
  Laboratoire Informatique           École Polytechnique de Montréal,
 d’Avignon (UAPV), France                          Canada
iria.dacunha@upf.edu                juan-manuel.torres@univ-
                                               avignon.fr


                                                            Thompson (1988), the web site of RST 1 and the
                     Abstract                               RST review by Taboada and Mann (2006a).
                                                                RST has been used to develop several
    In this article we present the RST Spanish
                                                            applications, like automatic summarization,
    Treebank, the first corpus annotated with
                                                            information extraction (IE), text generation,
    rhetorical relations for this language. We
                                                            question-answering, automatic translation, etc.
    describe the characteristics of the corpus,
                                                            (Taboada and Mann, 2006b). Nevertheless, most of
    the annotation criteria, the annotation
                                                            these works have been developed for English,
    procedure, the inter-annotator agreement,
                                                            German or Portuguese. This is due to the fact that
    and other related aspects. Moreover, we
                                                            at present corpora annotated with RST relations are
    show the interface that we have developed
                                                            available only for these languages (for English:
    to carry out searches over the corpus’
                                                            Carlson et al., 2002, Taboada and Renkema, 2008;
    annotated texts.
                                                            for German: Stede, 2004; for Portuguese: Pardo et
                                                            al., 2008) and there are automatic RST parsers for
1    Introduction                                           two of them (for English: Marcu, 2000; for
                                                            Portuguese: Pardo et al., 2008) or automatic RST
The Rhetorical Structure Theory (RST) (Mann and             segmenters (for English: Tofiloski et al., 2009).
Thompson, 1988) is a language independent theory            Scientific community working on RST applied to
based on the idea that a text can be segmented into         Spanish is very small. For example, Bouayad-Agha
Elementary Discourse Units (EDUs) linked by                 et al. (2006) apply RST to text generation in
means of nucleus-satellite or multinuclear                  several languages, Spanish among them. Da Cunha
rhetorical relations. In the first case, the satellite      et al. (2007) develop a summarization system for
gives additional information about the other one,           medical texts in Spanish based on RST. Da Cunha
the nucleus, on which it depends (ex. Result,               and Iruskieta (2010) perform a contrastive analysis
Condition, Elaboration or Concession). In the               of Spanish and Basque texts. Romera (2004)
second case, several elements, all nuclei, are              analyzes coherence relations by means of RST in
connected at the same level, that is, there are no          spoken Spanish. Taboada (2004) applies RST to
elements dependent on others and they all have the          analyze the resources used by speakers to elaborate
same importance with regard to the intentions of            conversations in English and Spanish.
the author of the text (ex. Contrast, List, Joint or            We consider that it is necessary to build a
Sequence). The rhetorical analysis of a text by             Spanish corpus annotated by means of RST. This
means of RST includes 3 phases: segmentation,               corpus should be useful for the development of a
detection of relations and building of hierarchical         rhetorical parser for this language and several other
rhetorical trees. For more information about RST            applications related to computational linguistics,
we recommend the original article of Mann and               like those developed for other languages

                                                            1
                                                                http://www.sfu.ca/rst/index.html

                                                       1

                           Proceedings of the Fifth Law Workshop (LAW V), pages 1–10,
               Portland, Oregon, 23-24 June 2011. c 2011 Association for Computational Linguistics
(automatic translation, automatic summarization,         specified and it does not include texts annotated by
IE, etc.). And that is what we pretend to achieve        several people.
with our work. We present the development of the             Another well-known corpus is the Potsdam
RST Spanish Treebank, the first Spanish corpus           Commentary Corpus, for German (Stede, 2004;
annotated by means of RST.                               Reitter and Stede, 2003). This corpus includes 173
    In Section 2, we present the state of the art        texts on politics from the on-line newspaper
about RST annotated corpora. In Section 3, we            Märkische Allgemeine Zeitung. It contains 32,962
explain the characteristics of the RST Spanish           words and 2,195 sentences. It is annotated with
Treebank. In Section 4, we show the search               several data: morphology, syntax, rhetorical
interface we have developed. In Section 5, we            structure, connectors, correference and informative
establish some conclusions and future work.              structure. Nevertheless, only a part of this corpus
                                                         (10 texts), which the authors name "core corpus",
2      State of the Art                                  is annotated with all this information. The texts
                                                         were annotated with the RSTtool. This corpus has
The most known RST corpus is the RST Discourse
                                                         several advantages: it is annotated at different
Treebank, for English (Carlson et al., 2002a,
                                                         levels (the annotation of connectors is especially
2002b). It includes 385 texts of the journalistic
                                                         interesting); all the texts were annotated by two
domain, extracted from the Penn Treebank
                                                         people (with a previous RST training phase); it is
(Marcus et al., 1993), such as cultural reviews,
                                                         free for research purposes, and there is a tool for
editorials, economy articles, etc. 347 texts are used
                                                         searching over the corpus (although it is not
as a learning corpus and 38 texts are used as a test
                                                         available on-line). The disadvantages are: the
corpus. It contains 176,389 words and 21,789
                                                         genre and domain of all the texts are the same, the
EDUs. 13.8% of the texts (that is, 53) were
                                                         methodology of annotation was quite intuitive
annotated by two people with a list of 78 relations.
                                                         (without a manual or specific criteria) and the
For annotation, the annotation tool RSTtool 2
                                                         inter-annotator agreement is not given.
(O'Donnell, 2000) was used, with some
                                                             For Portuguese, there are 2 corpora, built in
adaptations. The principal advantages of this
                                                         order to develop a rhetorical parser (Pardo et al.,
corpus stand on the high number of annotated texts
                                                         2008). The first one, the CorpusTCC (Pardo et al.,
(for the moment it is the biggest RST corpus) and
                                                         2008), was used as learning corpus for detection of
the clarity of the annotation method (specified in
                                                         linguistic patterns indicating rhetorical relations. It
the annotation manual by Carlson and Marcu,
                                                         contains 100 introduction sections of computer
2001). However, some drawbacks remain. The
                                                         science theses (53,000 words and 1,350 sentences).
corpus is not free, it is not on-line and it only
                                                         To annotate the corpus a list of 32 rhetorical
includes texts of one domain (journalistic).
                                                         relations was used. The annotation manual by
   For English there is also the Discourse
                                                         Carlson and Marcu (2001) was adapted to
Relations Reference Corpus (Taboada and
                                                         Portuguese. The annotation tool was the ISI RST
Renkema, 2008). This corpus includes 65 texts
                                                         Annotation Tool 3 , an extension of the RSTtool.
(each one tagged by one annotator) of several types
                                                         The advantages of this corpus are: it is free, it
and from several sources: 21 articles from the Wall
                                                         contains an acceptable number of texts and words
Street Journal extracted from the RST Discourse
                                                         and it follows a specific annotation methodology.
Treebank, 30 movies and books’ reviews extracted
                                                         The disadvantage is: it only includes texts of one
from the epinions.com website, and 14 diverse
                                                         genre and domain, only annotated by one person.
texts, including letters, webs, magazine articles,
                                                             The second one, Rhetalho (Pardo and Seno,
newspaper editorials, etc. The tool used for
                                                         2005), was used as reference corpus for the parser
annotation was also the RSTtool. The advantages
                                                         evaluation. It contains 50 texts: 20 introduction
of this corpus are that it is free and on-line, and it
                                                         sections and 10 conclusion sections from computer
includes texts of several types and domains. The
                                                         science scientific articles, and 20 texts from the on-
disadvantages are that the amount of texts is not
                                                         line newspaper Folha de São Paulo (7 from the
very high, the annotation methodology is not
                                                         Daily section, 7 from the World section and 6 from

2                                                        3
    http://www.wagsoft.com/RSTTool/                          http://www.isi.edu/~marcu/discourse/

                                                    2
the Science section). It includes approximately           author of the text is a specialist, and the potential
5,000 words. The relations and the annotation tool        reader of that text is a student or someone
are the same as those used in the CorpusTCC. The          interested in or possessing some prior knowledge
advantages of this corpus are that it is free, it was     about the subject) and low (the author of the text is
annotated by 2 people (they both were RST experts         a specialist, and the potential reader is the general
and followed an annotation manual) and it contains        public). The RST Spanish Treebank includes
texts of several genres and domains. The main             specialized texts of the three mentioned levels:
disadvantage is the scarce amount of texts.               high (scientific articles, conference proceedings,
    The Penn Discourse Treebank (Rashmi et al.,           doctoral theses, etc.), average (textbooks) and low
2008)f for English includes texts annotated with          (articles and reports from popular magazines,
information related to discourse structure and            associations’ websites, etc.). The texts have been
semantics (without a specific theoretical approach).      divided in 9 domains (some of them including
Its advantages are: its big size (it contains 40,600      subdivisions):       Astrophysics,        Earthquake
annotated discourse relations) allows to apply            Engineering, Economy, Law, Linguistics (Applied
machine learning, and the discourse annotations           Linguistics,     Language      Acquisition,     PLN,
are aligned with the syntactic constituency               Terminology), Mathematics (Primary Education,
annotations of the Penn Treebank. Its limitations         Secondary Education, Scientific Articles),
are: dependencies across relations are not marked,        Medicine (Administration of Health Services,
it only includes texts of the journalistic domain,        Oncology, Orthopedy), Psychology and Sexuality
and it is not free. Although there are several            (Clinical Perspective, Psychological Perspective).
corpora annotated with discourse relations, there is          The size of a corpus is also a polemic question.
not a corpus of this type for Spanish.                    If the corpus is developed for machine learning, its
                                                          size will be enough when the application we want
3     The RST Spanish Treebank                            to develop obtains acceptable percentages of
                                                          precision and recall (in the context of that
As Sierra (2008) states, a corpus consists of a
                                                          application). Nevertheless, if the corpus is built
compilation of a set of written and/or spoken texts
                                                          with descriptive purposes, it is difficult to
sharing some characteristics, created for certain
                                                          determine the corpus size. In the case of a corpus
investigation purposes. According to Hovy (2010),
                                                          annotated with rhetorical relations, it is even more
we use 7 core questions in corpus design, detailed
                                                          difficult, because there are various factors
in the next subsections.
                                                          involved: EDUs, SPANs (that is, a group of related
3.1    Selecting a Corpus                                 EDUs), nuclearity and relations. In addition,
                                                          relations are multiple (we use 28). As Hovy (2010:
For the RST Spanish Treebank, we wanted to                13) mentions, one of the most difficult phenomena
include short texts (finally, the average is 197          to annotate is the discourse structure. Our corpus
words by text; the longest containing 1,051 words         contains 52,746 words and 267 texts. Table 1
and the shortest, 25) in order to get a best on-line      includes RST Spanish Treebank statistics in terms
visualization of the RST trees. Moreover, in the          of texts, words, sentences and EDUs.
first stage of the project, we preferred to select
specialized texts of very different areas, although                          Texts   Words    Sentences   EDUs

in the future we plan to include also non-                 Learning corpus    183    41,555     1,759       2,655
specialized texts (ex. blogs, news, websites) in           Test corpus        84     11,191     497         694
order to guarantee the representativity of the             Total corpus       267    52,746     2,256       3,349
corpus. We did not find a pre-existing Spanish
                                                                 Table 1: RST Spanish Treebank statistics
corpus with these characteristics, so we decided to
build our own corpus. Following Cabré (1999), we              To increase the linear performance of a
consider that a text is specialized if it is written by   statistical method, it is necessary that the training
a professional in a given domain. According to this       corpus size grows exponentially (Zhao et al.,
work, specialized texts can be divided in three           2010). However, the RST Spanish Treebank is not
levels: high (both the author and the potential           designed only to use statistical methods; we think
reader of the text are specialists), average (the         it will be useful to employ symbolic or hybrid


                                                     3
algorithms (combining symbolic and statistical                      Relation     Type            Quantity
methods). Moreover, this corpus will be dynamic,
                                                                                           Nº                %
so we expect to have a bigger corpus in the future,
                                                           Elaboration           N-S       765              24.56
useful to apply machine learning methods.
    If we measure the corpus size in terms of words        Preparation           N-S       475              15.25
or texts, we can take as a reference the other RST         Background            N-S       204              6.55
corpora. Nevertheless, as Sierra states (2008), it is      Result                N-S       193              6.20
“absurd” to try to build an exhaustive corpus              Means                 N-S       175              5.62
covering all the aspects of a language. On the             List                  N-N       172              5.52
contrary,      the     linguist    looks     for     the
                                                           Joint                 N-N       160              5.14
representativeness of the texts, that is, tries to
create a sample of the studied language, selecting         Circumstance          N-S       140              4.49
examples which represent the linguistic reality, in        Purpose               N-S       122              3.92
order to analyze them in a pertinent way. In this          Interpretation        N-S       88               2.83
sense and in the frame of this work, we consider           Antithesis            N-S       80               2.57
that the size will be adequate if the rhetorical trees     Cause                 N-S       77               2.47
of the corpus include a representative number of
                                                           Sequency              N-N       74               2.38
examples of rhetorical relations, at least 20
examples of each one (taking into account that the         Evidence              N-S       59               1.89
corpus contains 3115 relations, we consider that           Contrast              N-N       58               1.86
this quantity is acceptable; however, we expect to         Condition             N-S       53               1.70
have even more examples when the corpus grows).            Concession            N-S       50               1.61
Table 2 shows the number of examples of each               Justification         N-S       39               1.25
relation currently included into the RST Spanish
                                                           Solution              N-S       32               1.03
Treebank (N-S: nucleus-satellite relation; N-N:
multinuclear relation). As it can be observed, it          Motivation            N-S       28               0.90

contains more than 20 examples of most of the              Reformulation         N-S       22               0.71
relations. The exceptions are the nucleus-satellite        Otherwise             N-S        3               0.10
relations of Enablement, Evaluation, Summary,              Conjunction           N-N       11               0.35
Otherwise and Unless, and the multinuclear                 Evaluation            N-S       11               0.35
relations of Conjunction and Disjunction, because
                                                           Disjunction           N-N        9               0.29
it is not so usual to find these rhetorical relations in
the language, in comparison with others. Hovy              Summary               N-S        8               0.26

(2010: 128) states that, given the lack of examples        Enablement            N-S        5               0.16
in the corpus, there are 2 possible strategies: a) to      Unless                N-S        2               0.06
leave the corpus as it is, with few or no examples
                                                           Table 2: Rhetorical relations in RST Spanish Treebank
of some cases (but the problem will be the lack of
training examples for machine learning systems),
or b) to add low-frequency examples artificially to        3.2       Instantiating the Theory
“enrich” the corpus (but the problem will be the           Our segmentation and annotation criteria are very
distortion of the native frequency distribution and        similar to the original ones used by Mann and
perhaps the confusion of machine learning                  Thompson (1988) for English, and by da Cunha
systems). In the current state of our project, we          and Iruskieta (2010) for Spanish. We also explore
have chosen the first option. We think that,               the annotation manual for English by Carlon and
including specialized texts in a second stage, we          Marcu (2001). Though we use some of their
will get more examples of these less common                postulates, we think that their analysis is too
relations. If we carry out a more granulated               meticulous in some aspects. Because of this, we
segmentation maybe we could obtain more                    consider that it is not adjusted to our interest,
examples; however, we wanted to employ the                 which is the finding of the simplest and most
segmentation criteria used to develop the Spanish          objective annotation method, orientated to the
RST discourse segmenter (da Cunha et al., 2011).

                                                      4
future development of a rhetorical parser for                      terminología científica serbia,] [una tendencia a
Spanish. To sum up, our segmentation criteria are:                 importar préstamos del inglés.]
                                                                         [In previous decades it has been shown,] [and it has been
a) All the sentences of the text are segmented as                  testified by many researchers of the scientific Serbian
EDUs (we consider that a sentence is a textual                     terminology,] [a trend to import loanwords from English.]
passage between a period and another period, a
semicolon, a question mark or an exclamation
point; texts’ titles are also segmented). Exs.4
[Éstas son las razones fundamentales que motivaron
este trabajo.]
   [These are the fundamental reasons which motivated this
work.]
[Estudio de caso único sobre violencia conyugal]
    [Study of a case on conjugal violence]                             Figure 1: Example of the non-relation Same-Unit
b) Intra-sentence EDUs are segmented, using the                    3.3    Designing the Interface
following criteria:
                                                                   The annotation tool used in this work is the
b1) An intra-sentence EDU has to include a finite                  RSTtool, since it is free and easy to use. Therefore,
verb, an infinitive or a gerund. Ex.                               we preferred to use it instead of designing a new
[Siendo una variante de la eliminación Gaussiana,]                 one. Nevertheless, we have designed an on-line
[posee características didácticas ventajosas.]                     interface to include the corpus and to carry out
   [Being a variant of Gaussian elimination,] [it possesses        searches over it (see Section 4).
didactic profitable characteristics.]
b2) Subject/object subordinate clauses                       or    3.4    Selecting and Training the Annotators
substantive sentences are not segmented. Ex.                       With regard to the corpus annotators, we have a
[Se muestra que el modelo discreto en diferencias finitas          team of 10 people (last year Bachelor’s degree
es convergente y que su realización se reduce a resolver           students, Master’s degree students and PhDs) 5 .
una sucesión de sistemas lineales tridiagonales.]                  Before the annotation, they took a RST course of 6
    [It appears that the discreet model in finite differences is
convergent and that its accomplishment is to solve a
                                                                   months (100 hours), where the segmentation and
succession of tridiagonal linear systems.]                         annotation methodology used for the development
                                                                   of the RST Spanish Treebank was explained.6 We
b3) Subordinate relative clauses are not segmented.
                                                                   called this period "training phase". The course had
Ex.
                                                                   a theoretical and a practical part. In the theoretical
[Durante el proceso, que utiliza solo aritmética entera,           part, some criteria with regard to the 3 phases of
se obtiene el determinante de la matriz de coeficientes            rhetorical analysis (segmentation, detection of
del sistema, sin necesidad de cálculos adicionales.]               relations, and rhetorical trees building) were given
    [During the process, which only uses entire arithmetic, the
determinant of the system coefficient matrix is obtained,          to annotators. In the practical part, firstly, it was
without additional calculations.]                                  explained how to use the RSTtool. Secondly,
                                                                   annotators extracted several texts from the web,
b4) Elements in parentheses are only segmented if
                                                                   following their personal interests, as for example,
they follow the criterion b1. Ex.
[Este año se cumple el bicentenario del nacimiento de
                                                                   music, video games, cookery or art webs. They
Niels (Nicolás, en nuestro idioma) Henrik Abel.]                   segmented those texts, using the established
     [This year is the bicentenary of Niels's birth (Nicolás, in   segmentation criteria. Once segmented, all the
our language) Henrik Abel.]                                        doubts and problematic examples were discussed,
b5) Embedded units are segmented by means of                       and they tried to get an agreement on the most
the non-relation Same-Unit proposed by Carlon                      complicated cases. Thirdly, the relations were
and Marcu (2001). Figure 1 shows this structure.
                                                                   5
                                                                     We thank annotators (Adriana Valerio, Brenda Castro,
[En décadas precedentes se ha puesto de manifiesto,] [y            Daniel Rodríguez, Ita Cruz, Jessica Méndez, Josué Careaga,
así lo han atestiguado muchos investigadores de la                 Luis Cabrera, Marina Fomicheva and Paulina De La Vega)
                                                                   and interface developers (Luis Cabrera and Juan Rolland).
4                                                                  6
  Spanish examples were extracted from the corpus. English           This course was given in the framework of a last-year subject
translations are ours.                                             in the Spanish Linguistics Degree at UNAM (Mexico City).

                                                              5
analyzed (using a given relations list) and, once          that there are so many categories to annotate, that
again, annotators discussed the difficult cases.           is very difficult to obtain a stable annotation.
After the discussion, texts were re-annotated to           Therefore, we consider it is necessary to have at
verify if the difficulties were solved. This process       least some texts double-annotated (or even triple-
was doubly interesting, since it helped to create          annotated), in order to have an adequate discourse
common criteria for the annotation of the final            corpus. This is the reason why, following the RST
corpus and to define the annotation criteria more          Discourse Treebank methodology, we use some
clearly and consensually, in order to include them         texts as learning corpus and some others (from the
in the RST Spanish Treebank annotation manual.             Mathematics, Psychology and Sexuality domains)
Once annotators agreed on the most difficult cases,        as test corpus: 69% (183 texts) and 31% (84 texts),
we consider that the training phase finished.              respectively. The texts of the learning corpus were
                                                           annotated by 1 person, whereas the texts of the test
3.5   Designing and Managing the Annotation                corpus were annotated by 2 people.
      Procedure
We start from the following annotation definition:
                                                           3.6   Validating Results
   Annotation (‘tagging’) is the process of adding new     Da Cunha and Iruskieta (2010) measure inter-
   information into source material by humans              annotator agreement by using the RST trees
   (annotators) or suitably trained machines. [...]. The   comparison methodology by Marcu (2000). This
   addition process usually requires some sort of          methodology evaluates the agreement on 4
   mental decision that depends both on the source         elements (EDUs, SPANs, Nuclearity and
   material and on some theory or knowledge that the       Relations), by means of precision and recall
   annotator has internalized earlier. (Hovy, 2010: 6)     measures (an annotation with regard to the other
    Exactly, after our annotators internalized the         one). Following this methodology, we have
theory and annotation criteria during the training         measured inter-annotator agreement over the test
phase, the "annotation phase" of the final texts           corpus. We employ an on-line automatic tool for
included in the RST Spanish Treebank started. In           RST trees comparison, RSTeval (Mazeiro and
this phase, the annotation tasks were assigned to          Pardo, 2009), where Marcu’s methodology has
annotators (the number of texts assigned to each           been implemented (for 4 languages: English,
annotator was different, depending on their                Portuguese, Spanish and Basque). We know that
availability). They were asked to carry out the            there are some other ways to measure agreement,
annotation individually and without questions              such as Cohen's kappa (Cohen, 1960) or Fleiss's
among them. We calculated that the average time            kappa (Fleiss, 1971), for example. Nevertheless,
to carry out the annotation of one text was between        we consider that Marcu's methodology (2000) is
15 minutes and 1 hour. This time difference is due         suitable to compare adequately 2 annotations of the
to the fact that the corpus includes both short and        same original text, because it has been designed
long texts. The annotation process is the following:       specifically for this task.
once a text is segmented, rhetorical relations                For each trees pair from the test corpus,
between EDUs are annotated. First, EDUs inside             precision and recall were measured separately.
the same sentence are annotated in a binary way.           Afterwards, all those individual results were put
Second, sentences inside the same paragraph are            together to obtain general results. Table 3 shows
linked. Finally, paragraphs are linked.                    global results for the 4 categories. The category
    Hovy (2010) states that it is difficult to             with more agreement was EDUs (recall: 91.04% /
determine if, for the same money (we add “for the          precision: 87.20%), that is, segmentation. This
same time”), it is better to double-annotate less, or      result was expected, since the segmentation criteria
to single-annotate more. As he explains, Dligach et        given to the annotators were quite precise and the
al. (2010) made an experiment with OntoNotes               possibility of mistake was low. The lowest
(Pradhan et al., 2007) verb sense annotation. The          agreement was obtained for the category Relations
result was that, assuming the annotation is stable         (recall: 78.48% / precision: 76.81%). This result is
(that is, inter-annotator agreement is high), it is        lower than the other, but we think it is acceptable.
better to annotate more, even with only one                In the RST Discourse Treebank the trend was
annotator. The problem with RST annotation is              similar to the one detected in our corpus: the

                                                      6
highest agreement is obtained at the segmentation              annotation of the texts, using the refined manual, in
level and the lowest at the relations level.                   order to check if the agreement increases, in the
                                                               same way as the RST Discourse Treebank.
      Category              Precision         Recall
                                                                  With regard to rhetorical annotations, we
  EDUs                      87.20%            91.04%           detected 2 main reasons of inter-annotator
  SPANs                       86%             87.31%           disagreement. The first one was the ambiguity of
  Nuclearity                82.46%            84.66%           some relations and their corresponding connectors;
  Relations                 76.81%            78.48%           for example, Justification-Reason, Antithesis-
                                                               Concession or Circumstance-Means relations, like
              Table 3: Inter-annotator agreement               in the following passage (in Spanish, “al” may
   Precision and recall have not been calculated               indicate time or manner):
with respect to a gold standard because it does not            [Los niños      aprenden    matemáticas]     [al   resolver
exist for Spanish. Our future aim is to reach a                problemas.]
consensus on the annotation of the test corpus                    [Children learn mathematics] [when solving problems.]
(using an external "judge"), in order to establish a              The second one is due to differences between
set of texts considered as a preliminary gold                  annotators when determining nuclearity. For
standard for this language. We consider that the               example, in the following passage, one annotator
annotations have quality at present, because inter-            marked Background and the other one Elaboration:
annotator agreement is quite high; however, this
                                                               [Quedó un hueco en la pared de                     60 x
consensus could solve the typical annotation                   1.20cm.]S_Background [Norma y Andrés               quieren
mistakes we have detected or some ambiguities.                 colocar en el hueco una pecera. ]N_Background
   We have analyzed the main discrepancy reasons               [Quedó un hueco en la pared de                      60 x
between annotators. With regard to the                         1.20cm.]N_Elaboration [Norma y Andrés              quieren
segmentation, the main one was human mistake;                  colocar en el hueco una pecera. ]S_Elaboration
ex. segmenting EDUs without a verb (one                          [A hole of 60 x 1.20 cm remained in the wall.] [Norma and
annotator segmented the following passage into 2               Andrés want to place a fish tank in the hole.]
EDUs because she detected a Means relation, but                   It is easier to solve segmentation disagreement
the second EDU does not include any verb):                     than relations disagreement, since in this case
[Además estudiamos el desarrollo de criterios para             annotator subjectivity is more evident; we must
determinar si un semigrupo dado tiene dicha propiedad ]        consider how to refine our manual in this sense.
[mediante el estudio de desigualdades de curvatura-
dimensión. ]                                                   3.7    Delivering and Maintaining the Product
    [We also study the development of tests in order to
determine if a given semi group has this property] [by means   Hovy (2010) mentions some technical issues
of curvature-dimension inequalities.]                          regarding these points: licensing, distribution,
                                                               maintenance and updates. With regard to licensing
    The second reason was that in the manual some
                                                               and distribution, the RST Spanish Treebank will be
aspects were not explained in detail. For example,
                                                               free for research purposes. We have a data
if a substantive sentence or a direct/object clause
                                                               manager responsible for maintenance and updates.
(which must not be segmented, according to the
                                                                   The description of the annotated corpus is also
point b2) includes two coordinated clauses, these
                                                               a very important issue (Ide and Pustejovsky, 2010).
must not be segmented either. Thus, we found
                                                               It is important to provide a high level description
some erroneous segmentations. For example:
                                                               of the corpus, including the theoretical framework,
[Los hombres adultos tienen miedo de fracasar] [y no           the methodology (annotators, annotation manual
cumplir con el rol masculino de ser proveedores del            and tool, agreement, etc.), the means for resource
hogar y de proteger a su familia.]
    [Adult men are scared to fail] [and not to fulfill the
                                                               maintenance, the technical aspects, the project
masculine role of being the suppliers of the home and to       leader, the contact, the team, etc. The RST Spanish
protect their family.]                                         Treebank includes all this detailed information.
   This kind of mistakes allowed us to refine our                  XML (with a DTD) has been used, in order the
segmentation manual a posteriori. In the future, we            corpus can be reused for several aplications. In the
will ask the test corpus annotators to make a new              future, we plan to use the standard XCES.


                                                          7
   To know more about resources development,               interface's applications, using their own
linguistic annotation or inter-annotator agreement,        subcorpora. The only requirement is to use the
we recommend: Palmer et al. (on-line), Palmer and          relations and the segmentation and annotation
Xue (2010), and Artstein and Poesio (2008).                criteria of our project. Once the texts are sent, the
                                                           RST Spanish Treebank data manager will verify if
4       The Search Interface of the RST                    the annotation corresponds to these criteria.
        Spanish Treebank
                                                           5    Conclusions and Future Work
The RST Spanish Treebank interface is freely
available on-line7. It allows the visualization and        We think that this work means an important step
downloading of all the texts in txt format, with           for the RST research in Spanish, and that the RST
their corresponding annotated trees in RSTtool             Spanish Treebank will be useful to carry out
format (rs3), as well as in image format (jpg). Each       diverse researches about RST in this language,
text includes its title, its reference, its web link (if   from a descriptive point of view (ex. analysis of
it is an on-line text) and its number of words. The        texts from different domains or genres) and an
interface shows texts by areas and allows the user         applied point of view (development of discourse
to select a subcorpus (including individual files or       parsers and NLP applications, like automatic
folders containing several files). The selected            summarization, automatic translation, IE, etc.).
subcorpus can be saved on local disk (generating a            For the moment the corpus' size is acceptable
xml file) for future analyses.                             and, though the percentage of double-annotated
    The interface includes a statistical tool which        texts is not very high, we think that having 10
allows obtaining statistics of rhetorical relations in     annotators (using the same annotation manual)
a subcorpus selected by the user. The RSTtool also         avoids the bias of only one annotator. In addition,
offers this option but it can be only used for one         the corpus includes texts of diverse domains and
text. We consider that it is more useful for the user      genres, which provides us with a heterogeneous
to obtain statistics from various texts, in order to       Spanish corpus. Moreover, the corpus interface
get significant statistical results. As the RSTtool,       that we have designed allows the user to select a
our tool allows to count the multinuclear relations        subcorpus and to analyze it statistically. In
in two ways: a) one unit for each detected                 addition, we think that it is essential to release a
multinuclear relation, and b) one unit for each            free corpus, on-line and dynamic, that is, in
detected nucleus. If we use b), the statistics of the      continuous growth. Nevertheless, we are conscious
multinuclear relations of Table 2 are higher: List         that our work still has certain limitations, which we
(864), Joint (537), Sequence (289), Contrast (153),        will try to solve in the future. In the short term, we
Conjunction (28) and Disjunction (24).                     have 5 aims:
    We are developing another tool, aimed to               a) To add one more annotator for the test corpus
extract information from the annotated texts, which        and to measure inter-annotator agreement.
we will soon include into the interface. This tool         b) To use more agreement measures, like kappa.
will allow to the user to select a subcorpus and to        c) To reach a consensus on the annotation of the
extract from it the EDUs corresponding to the              test corpus, in order to establish a set of texts
rhetorical relations selected, like a multidocument        considered as a preliminary gold standard.
specialized summarizer guided by user's interests.         d) To finish and to evaluate the IE tool.
    The RST Spanish Treebank interface also                e) To analyze the corpus to extract linguistic
includes a screen which permits the users to send          patterns for the automatic relations detection.
their own annotated texts. Our aim is for the RST
Spanish Treebank to become a dynamic corpus, in                In the long term, we consider other aims:
constant evolution, being increased with texts             f) To increase the corpus, by adding non-
annotated by users. This has a double advantage            specialized texts, and new domains and genres.
since, on the one hand, the corpus will grow and,          g) To annotate all the texts by 3 people, to get a
on the other hand, users will profit from the              representative gold-standard for Spanish (this aim
                                                           will depend on the funding of the project).
7
    http://www.corpus.unam.mx/rst/

                                                      8
References                                                   Joseph L. Fleis. 1971. Measuring nominal scale
                                                                agreement among many raters. Psychological
Ron Artstein, and Massimo Poesio. 2008. Survey                  Bulletin, 76(5):378-382.
  Article: Inter-Coder Agreement for Computational
  Linguistics. Computational Linguistics, 34(4):555-         Eduard Hovy. 2010. Annotation. A Tutorial. Presented
  596.                                                         at the 48th Annual Meeting of the Association for
                                                               Computational Linguistics.
Nadjet Bouayad-Agha, Leo Wanner, and Daniel
  Nicklass. 2006. Discourse structuring of dynamic           Nancy Ide and Pustejovsky, J. (2010). What Does
  content. Procesamiento del lenguaje natural, 37:207-         Interoperability Mean, anyway? Toward an
  213.                                                         Operational Definition of Interoperability. In
                                                               Proceedings of the Second International Conference
M. Teresa Cabré (1999). La terminología:                       on Global Interoperability for Language Resources
  representación y comunicación. Barcelona: IULA-              (ICGL 2010).
  UPF.
                                                             William C. Mann, and Sandra A. Thompson. 1988.
Lynn Carlson and Daniel Marcu. 2001. Discourse                 Rhetorical structure theory: Toward a functional
  Tagging Reference Manual. ISI Technical Report               theory of text organization. Text, 8(3):243-281.
  ISITR-545. Los Ángeles: University of Southern
  California.                                                Daniel Marcu. 2000. The Theory and Practice of
                                                               Discourse Parsing Summarization. Massachusetts:
Lynn Carlson, Daniel Marcu, and Mary Ellen                     Institute of Technology.
  Okurowski. 2002a. RST Discourse Treebank.
  Pennsylvania: Linguistic Data Consortium.                  Mitchell P. Marcus, Beatrice Santorini, Mary A.
                                                               Marcinkiewicz. 1993. Building a large annotated
Lynn Carlson, Daniel Marcu, and Mary Ellen                     corpus of English: the Penn Treenbank.
  Okurowski. 2002b. Building a Discourse-Tagged                Computational Linguistics, 19(2):313-330.
  Corpus in the Framework of Rhetorical Structure
  Theory. In Proceedings of the 2nd SIGDIAL                  Michael O’Donnell. 2000. RSTTOOL 2.4 – A markup
  Workshop on Discourse and Dialogue, Eurospeech               tool for rhetorical structure theory. In Proceedings of
  2001.                                                        the International Natural Language Generation
                                                               Conference. 253-256.
Jacob Cohen. 1960. A coefficient of agreement for
   nominal scales. Educational and Psychological             Martha Palmer, and Nianwen Xue. 2010. Linguistic
   Measurement, 20(1):37-46                                    Annotation. Handbook of Computational Linguistics
                                                               and Natural Language Processing.
Iria da Cunha, Eric SanJuan, Juan-Manuel Torres-
   Moreno, Marina Lloberes, and Irene Castellón. 2010.       Martha Palmer, Randee Tangi, Stephanie Strassel,
   Discourse Segmentation for Spanish based on                 Christiane Fellbaum, and Eduard Hovy (on-line).
   Shallow Parsing. Lecture Notes in Computer                  Historical Development and Future Directions in
   Science, 6437:13-23.                                        Data Resource Development. MINDS report.
                                                               http://www-nlpir.nist.gov/MINDS/FINAL/data.web.pdf
Iria da Cunha, and Mikel Iruskieta. 2010. Comparing
   rhetorical structures of different languages: The         Sameer Pradhan, Eduard Hovy, Mitch Marcus, Martha
   influence of translation strategies. Discourse Studies,     Palmer, Lance Ramshaw, Ralph Weischedel. 2007.
   12(5):563-598.                                              OntoNotes: A Unified Relational Semantic
                                                               Representation. In Proceedings of the First IEEE
Iria da Cunha, Leo Wanner, and M. Teresa Cabré. 2007.          International Conference on Semantic Computing
   Summarization of specialized discourse: The case of         (ICSC-07).
   medical articles in Spanish. Terminology, 13(2):249-
   286.                                                      Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni
                                                               Miltsakaki, Livio Robaldo, Aravind Joshi, and
Dmitriy Dligach, Rodney D. Nielsen, and Martha                 Bonnie Webber. 2008. The Penn Discourse Treebank
  Palmer. 2010. To Annotate More Accurately or to              2.0. In Proceedings of the 6th International
  Annotate More. In Proceedings of the 4th Linguistic          Conference on Language Resources and Evaluation
  Annotation Workshop (LAW-IV). 48th Annual                    (LREC 2008).
  Meeting of the Association for Computational
  Linguistics.                                               David Reitter, and Mandred Stede. 2003. Step by step:
                                                               underspecified markup in incremental rhetorical
                                                               analysis. In Proceedings of the 4th International



                                                        9
  Workshop on Linguistically Interpreted Corpora           conference on International Language Resources and
  (LINC-03).                                               Evaluation (LREC'10).
Magdalena Romera. 2004. Discourse Functional Units:
  The Expression of Coherence Relations in Spoken
  Spanish. Munich: LINCOM.
Thiago Alexandre Salgueiro Pardo, and Lucia Helena
  Machado Rino. 2001. A summary planner based on a
  three-level discourse model. In Proceedings of
  Natural Language Processing Pacific Rim
  Symposium. 533-538.
Thiago Alexandre Salgueiro Pardo, Maria das Graças
  Volpe Nunes, and Lucia Helena Machado Rino.
  2008. DiZer: An Automatic Discourse Analyzer for
  Brazilian Portuguese. Lecture Notes in Artificial
  Intelligence, 3171:224-234.
Thiago Alexandre Salgueiro Pardo, and Eloize Rossi
  Marques Seno. 2005. Rhetalho: um corpus de
  referência anotado retoricamente. In Anais do V
  Encontro de Corpora. São Carlos-SP, Brasil.
Gerardo Sierra. 2008. Diseño de corpus textuales para
  fines lingüísticos. In Proceedings of the IX Encuentro
  Internacional de Lingüística en el Noroeste 2. 445-
  462.
Manfred Stede. 2004. The Potsdam commentary corpus.
  In Proceedings of the Workshop on Discourse
  Annotation, 42nd Meeting of the Association for
  Computational Linguistics.
Maite Taboada. 2004. Building Coherence and
  Cohesion: Task-Oriented Dialogue in English and
  Spanish. Amsterdam/Philadelphia: John Benjamins.
Maite Taboada, and Jan Renkema. 2008. Discourse
  Relations Reference Corpus [Corpus]. Simon Fraser
  University       and        Tilburg       University.
  http://www.sfu.ca/rst/06tools/discourse_relations_cor
  pus.html.
Maite Taboada, and William C. Mann. 2006a.
  Rhetorical Structure Theory: Looking Back and
  Moving Ahead. Discourse Studies, 8(3):423-459.
Maite Taboada, and William C. Mann. 2006b.
  Applications of Rhetorical Structure Theory.
  Discourse Studies, 8(4):567-588.
Milan Tofiloski, Julian Brooke, and Maite Taboada.
  2009. A Syntactic and Lexical-Based Discourse
  Segmenter. In Proceedings of the 47th Annual
  Meeting of the Association for Computational
  Linguistics.
Hai Zhao, Yan Song, and Chunyu Kit. 2010. How Large
   a Corpus Do We Need: Statistical Method Versus
   Rule-based Method. In Proceedings of the Seventh


                                                     10
